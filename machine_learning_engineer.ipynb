{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "series = pd.Series()\n",
    "print('{}\\n'.format(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "dtype: int64\n",
      "\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int64\n",
      "\n",
      "0    1.0\n",
      "1    2.2\n",
      "dtype: float64\n",
      "\n",
      "0    1.0\n",
      "1    2.0\n",
      "dtype: float32\n",
      "\n",
      "0    [1, 2]\n",
      "1    [3, 4]\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "series = pd.Series(5)\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series([1, 2, 3])\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series([1, 2.2]) # upcasting\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "arr = np.array([1, 2])\n",
    "series = pd.Series(arr, dtype=np.float32)\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series([[1, 2], [3, 4]])\n",
    "print('{}\\n'.format(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "\n",
      "a      1\n",
      "8      2\n",
      "0.3    3\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#These integers are collectively referred to as the index of a Series, \n",
    "#and each individual index element is referred to as a label.\n",
    "#The default index is integers from 0 to n - 1, where n is the number of elements in the Series.\n",
    "\n",
    "series = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series([1, 2, 3], index=['a', 8, 0.3])\n",
    "print('{}\\n'.format(series))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "\n",
      "b    2\n",
      "a    1\n",
      "c    3\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The keys of the dictionary represent the index of the Series, \n",
    "#while each individual key is the label for its corresponding value.\n",
    "\n",
    "series = pd.Series({'a':1, 'b':2, 'c':3})\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series({'b':2, 'a':1, 'c':3})\n",
    "print('{}\\n'.format(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "   0\n",
      "0  5\n",
      "1  6\n",
      "\n",
      "   0  1\n",
      "0  5  6\n",
      "\n",
      "    c1  c2\n",
      "r1   5   6\n",
      "r2   1   3\n",
      "\n",
      "    c1  c2\n",
      "r1   1   3\n",
      "r2   2   4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "# Newline added to separate DataFrames\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.DataFrame([5, 6]) # Row Wise Representation\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.DataFrame([[5,6]]) # Column Wise Representation\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.DataFrame([[5, 6], [1, 3]],\n",
    "                  index=['r1', 'r2'],\n",
    "                  columns=['c1', 'c2'])\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.DataFrame({'c1': [1, 2], 'c2': [3, 4]},\n",
    "                  index=['r1', 'r2'])\n",
    "print('{}\\n'.format(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  1\n",
      "0  5.0  6\n",
      "1  1.2  3\n",
      "\n",
      "0    float64\n",
      "1      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#When we initialize a DataFrame of mixed types, upcasting occurs on a per-column basis.\n",
    "\n",
    "upcast = pd.DataFrame([[5, 6], [1.2, 3]])\n",
    "print('{}\\n'.format(upcast))\n",
    "# Datatypes of each column\n",
    "print(upcast.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1\n",
      "0   5.0  6\n",
      "1   1.2  3\n",
      "r3  0.0  0\n",
      "\n",
      "     0  1\n",
      "0  5.0  6\n",
      "1  1.2  3\n",
      "2  0.0  0\n",
      "\n",
      "     0  1\n",
      "0  5.0  6\n",
      "1  1.2  3\n",
      "0  0.0  0\n",
      "1  9.0  9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append function returns the modified DataFrame but doesn't actually change the original.\n",
    "# append function for concatenating DataFrame rows.\n",
    "#when we append a Series to the DataFrame, we either need to specify the name for the series \n",
    "#or use the ignore_index keyword argument. Setting ignore_index=True will change the row labels to integer indexes.\n",
    "\n",
    "df = pd.DataFrame([[5, 6], [1.2, 3]])\n",
    "ser = pd.Series([0, 0], name='r3')\n",
    "\n",
    "df_app = df.append(ser)\n",
    "print('{}\\n'.format(df_app))\n",
    "\n",
    "df_app = df.append(ser, ignore_index=True)\n",
    "print('{}\\n'.format(df_app))\n",
    "\n",
    "df2 = pd.DataFrame([[0,0],[9,9]])\n",
    "df_app = df.append(df2)\n",
    "print('{}\\n'.format(df_app))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c3\n",
      "r2   2   4   6\n",
      "\n",
      "    c2\n",
      "r1   3\n",
      "r2   4\n",
      "\n",
      "    c1  c2  c3\n",
      "r1   1   3   5\n",
      "\n",
      "    c1  c3\n",
      "r1   1   5\n",
      "r2   2   6\n",
      "\n",
      "    c1  c3\n",
      "r1   1   5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The first way is using the labels keyword argument to specify the labels of the rows/columns we want to drop.\n",
    "#The second method is to directly use the index or columns keyword arguments to specify the labels of the rows \n",
    "#or columns directly, without needing to use axis.\n",
    "#the drop function returns the modified DataFrame but doesn't actually change the original.\n",
    "#Note that when using labels and axis, we can't drop both rows and columns from the DataFrame.\n",
    "#Axis: 0 -> row, 1-> column\n",
    "\n",
    "df = pd.DataFrame({'c1': [1, 2], 'c2': [3, 4],\n",
    "                   'c3': [5, 6]},\n",
    "                  index=['r1', 'r2'])\n",
    "# Drop row r1\n",
    "df_drop = df.drop(labels='r1')\n",
    "print('{}\\n'.format(df_drop))\n",
    "\n",
    "# Drop columns c1, c3\n",
    "df_drop = df.drop(labels=['c1', 'c3'], axis=1)\n",
    "print('{}\\n'.format(df_drop))\n",
    "\n",
    "df_drop = df.drop(index='r2')\n",
    "print('{}\\n'.format(df_drop))\n",
    "\n",
    "df_drop = df.drop(columns='c2')\n",
    "print('{}\\n'.format(df_drop))\n",
    "\n",
    "df_drop = df.drop(index='r2', columns='c2')\n",
    "print('{}\\n'.format(df_drop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c1  c2\n",
      "r1   1   3   5   7\n",
      "r2   2   4   6   8\n",
      "\n",
      "    c1  c2\n",
      "r1   5   7\n",
      "r2   6   8\n",
      "r1   1   3\n",
      "r2   2   4\n",
      "0    5   7\n",
      "1    6   8\n",
      "\n",
      "     c1   c2   c1   c2\n",
      "r1  1.0  3.0  NaN  NaN\n",
      "r2  2.0  4.0  NaN  NaN\n",
      "0   NaN  NaN  5.0  7.0\n",
      "1   NaN  NaN  6.0  8.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To concatenate multiple DataFrames along either rows or columns, we use the pd.concat function.\n",
    "#concatenate the rows (axis=0, the default), or concatenate the columns (axis=1).\n",
    "\n",
    "df1 = pd.DataFrame({'c1':[1,2], 'c2':[3,4]},\n",
    "                   index=['r1','r2'])\n",
    "df2 = pd.DataFrame({'c1':[5,6], 'c2':[7,8]},\n",
    "                   index=['r1','r2'])\n",
    "df3 = pd.DataFrame({'c1':[5,6], 'c2':[7,8]})\n",
    "\n",
    "concat = pd.concat([df1, df2], axis=1)\n",
    "# Newline to separate print statements\n",
    "print('{}\\n'.format(concat))\n",
    "\n",
    "concat = pd.concat([df2, df1, df3])\n",
    "print('{}\\n'.format(concat))\n",
    "\n",
    "concat = pd.concat([df1, df3], axis=1)\n",
    "print('{}\\n'.format(concat))\n",
    "#This is because the row labels for df1 and df3 did not match, \n",
    "#so result was padded with NaN in locations where values did not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name pos  year\n",
      "0   john doe  1B  2000\n",
      "1   al smith   C  2004\n",
      "2  sam black   P  2008\n",
      "3   john doe  2B  2003\n",
      "\n",
      "       name  year  rbi\n",
      "0  john doe  2000   80\n",
      "1  al smith  2004  100\n",
      "2  jack lee  2012   12\n",
      "\n",
      "       name pos  year  rbi\n",
      "0  john doe  1B  2000   80\n",
      "1  al smith   C  2004  100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The function we use is pd.merge, which takes in two DataFrames for its two required arguments.\n",
    "#Without using any keyword arguments, pd.merge joins two DataFrames using all their common column labels. \n",
    "\n",
    "mlb_df1 = pd.DataFrame({'name': ['john doe', 'al smith', 'sam black', 'john doe'],\n",
    "                        'pos': ['1B', 'C', 'P', '2B'],\n",
    "                        'year': [2000, 2004, 2008, 2003]})\n",
    "mlb_df2 = pd.DataFrame({'name': ['john doe', 'al smith', 'jack lee'],\n",
    "                        'year': [2000, 2004, 2012],\n",
    "                        'rbi': [80, 100, 12]})\n",
    "                        \n",
    "print('{}\\n'.format(mlb_df1))\n",
    "print('{}\\n'.format(mlb_df2))\n",
    "\n",
    "mlb_merged = pd.merge(mlb_df1, mlb_df2)\n",
    "print('{}\\n'.format(mlb_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1    1\n",
      "r2    2\n",
      "Name: c1, dtype: int64\n",
      "\n",
      "    c1\n",
      "r1   1\n",
      "r2   2\n",
      "\n",
      "    c2  c3\n",
      "r1   3   5\n",
      "r2   4   6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'c1': [1, 2], 'c2': [3, 4],\n",
    "                   'c3': [5, 6]}, index=['r1', 'r2'])\n",
    "col1 = df['c1']\n",
    "# Newline for separating print statements\n",
    "print('{}\\n'.format(col1))\n",
    "\n",
    "col1_df = df[['c1']]\n",
    "print('{}\\n'.format(col1_df))\n",
    "\n",
    "col23 = df[['c2', 'c3']]\n",
    "print('{}\\n'.format(col23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c3\n",
      "r1   1   3   5\n",
      "r2   2   4   6\n",
      "\n",
      "    c1  c2  c3\n",
      "r1   1   3   5\n",
      "r2   2   4   6\n",
      "\n",
      "    c1  c2  c3\n",
      "r2   2   4   6\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'r1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'r1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-32418bd1cdc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Results in KeyError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'r1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'r1'"
     ]
    }
   ],
   "source": [
    "f = pd.DataFrame({'c1': [1, 2, 3], 'c2': [4, 5, 6],\n",
    "                   'c3': [7, 8, 9]}, index=['r1', 'r2', 'r3'])\n",
    "\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "first_two_rows = df[0:2]\n",
    "print('{}\\n'.format(first_two_rows))\n",
    "\n",
    "last_two_rows = df['r2':'r3']\n",
    "print('{}\\n'.format(last_two_rows))\n",
    "\n",
    "# Results in KeyError\n",
    "#when we tried to retrieve a single row based on its label, \n",
    "#we received a KeyError. This is because the DataFrame treated 'r1' as a column label.\n",
    "df['r1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c3\n",
      "r1   1   4   7\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n",
      "c1    2\n",
      "c2    5\n",
      "c3    8\n",
      "Name: r2, dtype: int64\n",
      "\n",
      "    c1  c2  c3\n",
      "r1   1   4   7\n",
      "r3   3   6   9\n",
      "\n",
      "    c1  c2  c3\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We use iloc to access rows based on their integer index. \n",
    "\n",
    "df = pd.DataFrame({'c1': [1, 2, 3], 'c2': [4, 5, 6],\n",
    "                   'c3': [7, 8, 9]}, index=['r1', 'r2', 'r3'])\n",
    "                   \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "print('{}\\n'.format(df.iloc[1]))\n",
    "\n",
    "print('{}\\n'.format(df.iloc[[0, 2]]))\n",
    "\n",
    "bool_list = [False, True, True]\n",
    "print('{}\\n'.format(df.iloc[bool_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c3\n",
      "r1   1   4   7\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n",
      "c1    2\n",
      "c2    5\n",
      "c3    8\n",
      "Name: r2, dtype: int64\n",
      "\n",
      "    c1  c2  c3\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n",
      "Single val: 4\n",
      "\n",
      "r1    4\n",
      "r3    6\n",
      "Name: c2, dtype: int64\n",
      "\n",
      "    c1  c2  c3\n",
      "r1   1   0   7\n",
      "r2   2   5   8\n",
      "r3   3   0   9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The loc property provides the same row indexing functionality as iloc, but uses row labels rather than integer indexes. \n",
    "\n",
    "df = pd.DataFrame({'c1': [1, 2, 3], 'c2': [4, 5, 6],\n",
    "                   'c3': [7, 8, 9]}, index=['r1', 'r2', 'r3'])\n",
    "                   \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "print('{}\\n'.format(df.loc['r2']))\n",
    "\n",
    "bool_list = [False, True, True]\n",
    "print('{}\\n'.format(df.loc[bool_list]))\n",
    "\n",
    "single_val = df.loc['r1', 'c2']\n",
    "print('Single val: {}\\n'.format(single_val))\n",
    "\n",
    "print('{}\\n'.format(df.loc[['r1', 'r3'], 'c2']))\n",
    "\n",
    "df.loc[['r1', 'r3'], 'c2'] = 0\n",
    "print('{}\\n'.format(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c1  c2  c3\n",
       "r1   1   0   7\n",
       "r3   3   0   9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_13 = df.iloc[[0,2]]\n",
    "row_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also filter the groups using filter. The filter function takes in another function as its required argument, \n",
    "#which specifies how we want to filter the groups. The output of filter is the concatenation of all the groups \n",
    "#that pass the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns of a DataFrame as the features of the dataset that it represents. These features can be quantitative or categorical.\n",
    "\n",
    "#A quantitative feature, e.g. height or weight, is a feature that can be measured numerically. \n",
    "#These are features we could calculate the sum, mean, or other numerical metrics for.\n",
    "\n",
    "#A categorical feature, e.g. gender or birthplace, is one where the values are categories that could be used \n",
    "#to group the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      T1      T2      T3\n",
      "0    0.1    0.25    0.16\n",
      "1  150.0  240.00  100.00\n",
      "\n",
      "      T1     T2      T3\n",
      "0    0.2    0.5    0.32\n",
      "1  300.0  480.0  200.00\n",
      "\n",
      "      T1     T2     T3\n",
      "0  100.0  250.0  160.0\n",
      "1  150.0  240.0  100.0\n",
      "\n",
      "      T1     T2     T3\n",
      "0  100.0  125.0  160.0\n",
      "1  150.0  120.0  100.0\n",
      "\n",
      "0    385.0\n",
      "1    370.0\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Along with aggregating quantitative features, we can also apply weights to them. We do this through the multiply function.\n",
    "#The multiply function takes in a list of weights or a constant as its required argument. \n",
    "#If a constant is used, the constant is multiplied across all the rows or columns (depending on the value of axis). \n",
    "#If a list is used, then the position of each weight in the list corresponds to which row/column it is multiplied to.\n",
    "#In contrast with sum and mean, the default axis for multiply is the columns axis. \n",
    "#Therefore, to multiply weights along the rows of a DataFrame, we need to explicitly set axis=0.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'T1': [0.1, 150.],\n",
    "  'T2': [0.25, 240.],\n",
    "  'T3': [0.16, 100.]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "print('{}\\n'.format(df.multiply(2)))\n",
    "\n",
    "df_ms = df.multiply([1000, 1], axis=0)\n",
    "print('{}\\n'.format(df_ms))\n",
    "\n",
    "df_w = df_ms.multiply([1,0.5,1])\n",
    "print('{}\\n'.format(df_w))\n",
    "print('{}\\n'.format(df_w.sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2   cruzne02    2016    SEA  43\n",
      "3  ortizda01    2016    BOS  38\n",
      "4   cruzne02    2017    SEA  39\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: playerID, dtype: bool\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "Name: HR, dtype: bool\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: teamID, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'cruzne02', 'ortizda01', 'cruzne02'],\n",
    "  'yearID': [2016, 2016, 2016, 2016, 2017],\n",
    "  'teamID': ['BOS', 'SEA', 'SEA', 'BOS', 'SEA'],\n",
    "  'HR': [31, 39, 43, 38, 39]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "cruzne02 = df['playerID'] == 'cruzne02'\n",
    "print('{}\\n'.format(cruzne02))\n",
    "\n",
    "hr40 = df['HR'] > 40\n",
    "print('{}\\n'.format(hr40))\n",
    "\n",
    "notbos = df['teamID'] != 'BOS'\n",
    "print('{}\\n'.format(notbos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2   cruzne02    2016    SEA  43\n",
      "3  ortizda01    2016    BOS  38\n",
      "4   cruzne02    2017    SEA  39\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: playerID, dtype: bool\n",
      "\n",
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "Name: teamID, dtype: bool\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: playerID, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For columns with string values, we can use str.startswith, str.endswith, and str.contains to filter for specific strings. \n",
    "\n",
    "df = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'cruzne02', 'ortizda01', 'cruzne02'],\n",
    "  'yearID': [2016, 2016, 2016, 2016, 2017],\n",
    "  'teamID': ['BOS', 'SEA', 'SEA', 'BOS', 'SEA'],\n",
    "  'HR': [31, 39, 43, 38, 39]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "str_f1 = df['playerID'].str.startswith('c')\n",
    "print('{}\\n'.format(str_f1))\n",
    "\n",
    "str_f2 = df['teamID'].str.endswith('S')\n",
    "print('{}\\n'.format(str_f2))\n",
    "\n",
    "str_f3 = ~df['playerID'].str.contains('o')\n",
    "print('{}\\n'.format(str_f3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2   cruzne02    2016    SEA  43\n",
      "3  ortizda01    2016    BOS  38\n",
      "4   cruzne02    2017    SEA  39\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "Name: playerID, dtype: bool\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "Name: yearID, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'cruzne02', 'ortizda01', 'cruzne02'],\n",
    "  'yearID': [2016, 2016, 2016, 2016, 2017],\n",
    "  'teamID': ['BOS', 'SEA', 'SEA', 'BOS', 'SEA'],\n",
    "  'HR': [31, 39, 43, 38, 39]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "isin_f1 = df['playerID'].isin(['cruzne02',\n",
    "                               'ortizda01'])\n",
    "print('{}\\n'.format(isin_f1))\n",
    "\n",
    "isin_f2 = df['yearID'].isin([2015, 2017])\n",
    "print('{}\\n'.format(isin_f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2   cruzne02    2016    SEA  43\n",
      "3  ortizda01    2016    BOS  38\n",
      "4   cruzne02    2017    SEA  39\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: teamID, dtype: bool\n",
      "\n",
      "0    True\n",
      "1    True\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "Name: teamID, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#when a Series or DataFrame has a missing value at a location, it is represented by NaN. \n",
    "#The NaN value in pandas is equivalent to np.nan in NumPy.\n",
    "#we cannot use a relation operation to create a filter condition for NaN values. Instead, we use the isna and notna functions.\n",
    "\n",
    "f = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'doejo01'],\n",
    "  'yearID': [2016, 2016, 2017],\n",
    "  'teamID': ['BOS', 'SEA', np.nan],\n",
    "  'HR': [31, 39, 99]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "isna = df['teamID'].isna()\n",
    "print('{}\\n'.format(isna))\n",
    "\n",
    "notna = df['teamID'].notna()\n",
    "print('{}\\n'.format(notna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2   cruzne02    2016    SEA  43\n",
      "3  ortizda01    2016    BOS  38\n",
      "4  bettsmo01    2015    BOS  18\n",
      "\n",
      "   playerID  yearID teamID  HR\n",
      "2  cruzne02    2016    SEA  43\n",
      "\n",
      "    playerID  yearID teamID  HR\n",
      "4  bettsmo01    2015    BOS  18\n",
      "\n",
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "3  ortizda01    2016    BOS  38\n",
      "4  bettsmo01    2015    BOS  18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'cruzne02', 'ortizda01', 'bettsmo01'],\n",
    "  'yearID': [2016, 2016, 2016, 2016, 2015],\n",
    "  'teamID': ['BOS', 'SEA', 'SEA', 'BOS', 'BOS'],\n",
    "  'HR': [31, 39, 43, 38, 18]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "hr40_df = df[df['HR'] > 40]\n",
    "print('{}\\n'.format(hr40_df))\n",
    "\n",
    "not_hr30_df = df[~(df['HR'] > 30)]\n",
    "print('{}\\n'.format(not_hr30_df))\n",
    "\n",
    "str_df = df[df['teamID'].str.startswith('B')]\n",
    "print('{}\\n'.format(str_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the sort_values function allows us to sort a DataFrame by one or more of its columns. \n",
    "#The first argument is either a column label or a list of column labels to sort by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas provides the describe function to obtain a summary of a DataFrame's numeric data.\n",
    "#To have describe return specific percentiles, we can use the percentiles keyword argument.\n",
    "#The percentiles argument takes in a list of decimal percentages, representing the percentiles we want returned in the summary.\n",
    "#Note that the 50th percentile, i.e. the median, is always returned. \n",
    "#The values specified in the percentiles list will replace the default 25th and 75th percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The frequency count for a specific category of a feature refers to how many times that category appears in the dataset. \n",
    "#In pandas, we use the value_counts function to obtain the frequency counts for each category in a column feature.\n",
    "#Setting normalize=True returns the frequency proportions, rather than counts, for each category \n",
    "#(note that the sum of all the proportions is 1). \n",
    "\n",
    "#If we just want the names of each unique category in a column, rather than the frequencies, we use the unique function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In pandas, we convert each categorical feature of a DataFrame to indicator features with the get_dummies function. \n",
    "#The function takes in a DataFrame as its required argument, and returns the DataFrame with each of its \n",
    "#categorical features converted to indicator features.\n",
    "#We can then convert to a NumPy matrix using the values function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
