{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'I am learning how to build chatbots')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'I am going to London next week for a meeting.')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Google release \"Move Mirror\" AI experiment that matches your pose from 80,000 images')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.tag_, token.pos_, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'I am learning how to build chatbots')\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lemmatizer import Lemmatizer\n",
    "#from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "#from spacy.lang.en import English\n",
    "#lemmatizer = English.Defaults.create_lemmatizer()\n",
    "#lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "lemmatizer = nlp.Defaults.create_lemmatizer()\n",
    "lemmatizer('chuckles','Noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer('blazing', 'VERB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer('fastest', 'ADJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "print(porter_stemmer.stem(\"fastest\"))\n",
    "print(snowball_stemmer.stem(\"fastest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = u\"Google has its headquarters in Mountain View, California having revenue amounted to 109.65 billion US dollars\"\n",
    "doc = nlp(my_string)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = u\"Mark Zuckerberg born May 14, 1984 in New York is an American technology entrepreneur and philanthropist best known for co-founding and leading Facebook as its chairman and CEO.\"\n",
    "doc = nlp(my_string)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = u\"I usually wake up at 9:00 AM. 90% of my daytime goes in learning new things.\"\n",
    "doc = nlp(my_string)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string1 = u\"Imagine Dragons are the best band.\"\n",
    "my_string2 = u\"Imagine dragons come and take over the city.\"\n",
    "doc1 = nlp(my_string1)\n",
    "doc2 = nlp(my_string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc1.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = u\"Imagine Dragons are the best band.\"\n",
    "doc = nlp(my_string)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = u\"Imagine dragons come and take over the city.\"\n",
    "doc = nlp(my_string)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab[u'is'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab[u'hello'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Book me a flight from Bangalore to Goa')\n",
    "blr, goa = doc[5], doc[7]\n",
    "list(blr.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(goa.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[3].is_ancestor(doc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Book a table at the restaurant and the taxi to the hotel')\n",
    "tasks = doc[2], doc[8] #(table, taxi)\n",
    "tasks_target = doc[5], doc[11] #(restaurant, hotel)\n",
    "\n",
    "for task in tasks_target:\n",
    "    for tok in task.ancestors:\n",
    "        if tok in tasks:\n",
    "            print(\"Booking of {} belongs to {}\".format(tok, task))\n",
    "            #break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(doc[3].children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(u'Book a table at the restaurant and the taxi to the hotel')\n",
    "displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"What are some places to visit in Berlin and stay in Lubeck\")\n",
    "places = [doc[7], doc[11]] #[Berlin, Lubeck]\n",
    "actions = [doc[5], doc[9]] #[visit, stay]\n",
    "\n",
    "for place in places:\n",
    "    for tok in place.ancestors:\n",
    "        if tok in actions:\n",
    "            print((\"User is referring {} to {}\").format(place, tok))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Boston Dynamics is gearing up to produce thousands of robot dogs\")\n",
    "list(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Deep learning cracks the code of messenger RNAs and protein-coding potential\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_doc = nlp(u\"hello\")\n",
    "hi_doc = nlp(u\"hi\")\n",
    "hella_doc = nlp(u\"hella\")\n",
    "print(hello_doc.similarity(hi_doc))\n",
    "print(hello_doc.similarity(hella_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoT_str1 = nlp(u\"When will next season of Game of Thrones be releasing?\")\n",
    "GoT_str2 = nlp(u\"Game of Thrones next season release date?\")\n",
    "GoT_str1.similarity(GoT_str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_doc = nlp(u\"car truck google\")\n",
    "\n",
    "for t1 in example_doc:\n",
    "    for t2 in example_doc:\n",
    "        similarity_perc = int(t1.similarity(t2) * 100)\n",
    "        print( \"Word {} is {}% similar to word {}\".format(t1.text, similarity_perc, t2.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Brexit is the impending withdrawal of the U.K. from the European Union.')\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = \"Book me a metro from Airport Station to Hong Kong Station.\"\n",
    "sentence1 = \"Book me a cab to Hong Kong Airport from AsiaWorld-Expo.\"\n",
    "\n",
    "import re\n",
    "from_to = re.compile('.* from (.*) to (.*)')\n",
    "to_from = re.compile('.* to (.*) from (.*)')\n",
    "\n",
    "from_to_match = from_to.match(sentence2)\n",
    "to_from_match = to_from.match(sentence2)\n",
    "\n",
    "if from_to_match and from_to_match.groups():\n",
    "    _from = from_to_match.groups()[0]\n",
    "    _to = from_to_match.groups()[1]\n",
    "    print(\"from_to pattern matched correctly. Printing values\\n\")\n",
    "    print(\"From: {}, To: {}\".format(_from, _to))\n",
    "elif to_from_match and to_from_match.groups():\n",
    "    _to = to_from_match.groups()[0]\n",
    "    _from = to_from_match.groups()[1]\n",
    "    print(\"to_from pattern matched correctly. Printing values\\n\")\n",
    "    print(\"From: {}, To: {}\".format(_from, _to))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasa-nlu==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/RasaHQ/rasa_nlu.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Using cached https://files.pythonhosted.org/packages/83/17/f00b4c5d6e19020e321ffb67ea137e79d4a96c482512975524ec7caa76e1/tensorflow_addons-0.9.1-cp37-cp37m-win_amd64.whl\n",
      "Collecting rasa\n",
      "  Using cached https://files.pythonhosted.org/packages/50/aa/e55644c4ae80837f9f6b6fdbe61aa6c6cfff3d2fb1c5fe3d3641fafba31c/rasa-1.10.0-py3-none-any.whl\n",
      "Collecting typeguard>=2.7 (from tensorflow-addons)\n",
      "  Using cached https://files.pythonhosted.org/packages/06/37/d236aec27f8a8eed66f1a17116eb51684528cf8005a6883f879fe2e842ae/typeguard-2.7.1-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: boto3<2.0,>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (1.13.8)\n",
      "Collecting tqdm<4.46,>=4.31 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl\n",
      "Collecting oauth2client==4.1.3 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/a9/4f25a14d23f0786b64875b91784607c2277eff25d48f915e39ff0cff505a/oauth2client-4.1.3-py2.py3-none-any.whl\n",
      "Collecting mattermostwrapper<2.3,>=2.2 (from rasa)\n",
      "Collecting sanic-jwt<1.5.0,>=1.3.2 (from rasa)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit<3.0,>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (2.0.10)\n",
      "Collecting fbmessenger<6.1.0,>=6.0.0 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/bd/e9/646684226176782b9e3b7dd5b35d7ecfd1d13cba24ad2e33255079921aab/fbmessenger-6.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: pytz<2020.0,>=2019.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (2019.3)\n",
      "Collecting rocketchat_API<1.4.0,>=0.6.31 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/42/12/055da56d3eb5012bb02c806ad4f3549d910147a10dee7ce4b89ccf23f388/rocketchat_API-1.3.1-py3-none-any.whl\n",
      "Collecting sanic<20.0.0,>=19.12.2 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/90/54/17f1e496599214dede67e37e019ce2f210b7861d2dd39b92ac4d3d08e83a/sanic-19.12.2-py3-none-any.whl\n",
      "Collecting questionary<1.6.0,>=1.5.1 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/7d/61b7d0da15bb50e7239c870771320026447b7e2d9490ee96f49dddd3ef0d/questionary-1.5.2-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (41.4.0)\n",
      "Collecting pydot<1.5,>=1.4 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: gevent<1.6,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (1.4.0)\n",
      "Collecting slackclient<3.0.0,>=2.0.0 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/01/5877fa0be43651bb0087388c5ee4a5bcedebc4d8c895fa63c80b74c2c611/slackclient-2.5.0-py2.py3-none-any.whl\n",
      "Collecting ruamel.yaml<0.17,>=0.16 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/a6/92/59af3e38227b9cc14520bf1e59516d99ceca53e3b8448094248171e9432b/ruamel.yaml-0.16.10-py2.py3-none-any.whl\n",
      "Collecting kafka-python<2.0,>=1.4 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/49/c9/9863483a1353700ba87821b4f39085eb18fd1bcbb1e954c697177d67f03f/kafka_python-1.4.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: tensorflow<2.2,>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (2.1.0)\n",
      "Collecting twilio<6.27,>=6.26 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/23/e6/630676e9749be27879957dcac080dbafa2a8bf2cf47db3f7247862dd6277/twilio-6.26.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: scipy<2.0.0,>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: ujson<3.0,>=1.35 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (2.0.3)\n",
      "Collecting python-socketio<4.6,>=4.4 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/10/cb/631c0b713daea3938e66d4c0923e88f3c0b57b026f860ea76e0337bc9c7a/python_socketio-4.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: SQLAlchemy<1.4.0,>=1.3.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (1.3.9)\n",
      "Collecting jsonpickle<1.5,>=1.3 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n",
      "Collecting scikit-learn<0.23,>=0.22 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/1f/e3/e400f94e368a7b0d2432a88ab671a7f27c9159f177bbed68f7cce83b5848/scikit_learn-0.22.2.post1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle<1.4,>=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (1.2.2)\n",
      "Collecting redis<4.0,>=3.4 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/29/90/8c3f7cd9c23cc259dd01979f03971e70fe2ddad79b93a70026716be20ded/redis-3.5.1-py2.py3-none-any.whl\n",
      "Collecting python-telegram-bot<13.0,>=11.1 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/96/8a/4c637ddfc1546fcc07dc580b5da58e60c279fb0c428976a470e93a166f26/python_telegram_bot-12.7-py2.py3-none-any.whl\n",
      "Collecting rasa-sdk<2.0.0,>=1.10.0 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/90/fd/39059cb7e5418fdc427669dd0b67008b4f8842fc0a2a5a427ec06bec84de/rasa_sdk-1.10.1-py3-none-any.whl\n",
      "Collecting colorclass<2.3,>=2.2 (from rasa)\n",
      "Collecting packaging<19.1,>=19.0 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/91/32/58bc30e646e55eab8b21abf89e353f59c0cc02c417e42929f4a9546e1b1d/packaging-19.0-py2.py3-none-any.whl\n",
      "Collecting multidict<5.0,>=4.6 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/3c/d1c93ae89f16f280a506b1ef02078d24865e3fa545177eeff1181b03265b/multidict-4.7.5-cp37-cp37m-win_amd64.whl\n",
      "Collecting pykwalify<1.8.0,>=1.7.0 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/36/9f/612de8ca540bd24d604f544248c4c46e9db76f6ea5eb75fb4244da6ebbf0/pykwalify-1.7.0-py2.py3-none-any.whl\n",
      "Collecting async_generator<1.11,>=1.10 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/52/39d20e03abd0ac9159c162ec24b93fbcaa111e8400308f2465432495ca2b/async_generator-1.10-py3-none-any.whl\n",
      "Collecting requests<3.0,>=2.23 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl\n",
      "Collecting tensorflow_hub<0.9,>=0.7 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/fb/9d/d5772f94e31431cdb56a8bb2c34d8839bb7d7621f2a5959f4ef43207d7ac/tensorflow_hub-0.8.0-py2.py3-none-any.whl\n",
      "Collecting jsonschema<3.3,>=3.2 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl\n",
      "Collecting coloredlogs<11.0,>=10.0 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/08/0f/7877fc42fff0b9d70b6442df62d53b3868d3a6ad1b876bdb54335b30ff23/coloredlogs-10.0-py2.py3-none-any.whl\n",
      "Collecting networkx<2.5.0,>=2.4.0 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl\n",
      "Collecting tensorflow-probability<0.10,>=0.7 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/9b/ed/f587d64127bbb85e539f06a2aace1240b7b5c6b4267bea94f232230551a5/tensorflow_probability-0.9.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator==2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (2.1.0)\n",
      "Collecting pika<1.2.0,>=1.1.0 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/a1/ae/8bedf0e9f1c0c5d046db3a7428a4227fe36ec1b8e25607f3c38ac9bf513c/pika-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<2.9,>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib<3.3,>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (3.1.1)\n",
      "Collecting aiohttp<3.7,>=3.6 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/0b/b3/744a16bdaba2e4df90f6ff10b9ade9c2dce3f01d94848f3949aa4ce7868d/aiohttp-3.6.2-cp37-cp37m-win_amd64.whl\n",
      "Collecting attrs<19.4,>=19.3 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: PyJWT<1.8,>=1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (1.7.1)\n",
      "Collecting python-engineio<3.13,>=3.11 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/6c/aa/c975982df73c4bcd087732db14b05306e8a3f3f24596cc18647746539290/python_engineio-3.12.1-py2.py3-none-any.whl\n",
      "Collecting psycopg2-binary<2.9.0,>=2.8.2 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/00/9c3cea3ed03140f66dd601e557f5b8e5244e6efae60fe557bce4bb71682c/psycopg2_binary-2.8.5-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (1.16.5)\n",
      "Collecting sanic-cors<0.11.0,>=0.10.0b1 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/33/5e1776669aa62dd9c65e3513425077915acb1758d6b19f08f830f27ce9a8/Sanic_Cors-0.10.0.post3-py2.py3-none-any.whl\n",
      "Collecting sklearn-crfsuite<0.4,>=0.3 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
      "Collecting terminaltables<3.2.0,>=3.1.0 (from rasa)\n",
      "Collecting pymongo[srv,tls]<3.9.0,>=3.8.0 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/57/b0/acf286a558e19dc0992354181c8650dffc79fced47a4555e49ca70acf426/pymongo-3.8.0-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied, skipping upgrade: absl-py<0.10,>=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from rasa) (0.9.0)\n",
      "Collecting colorhash<1.1.0,>=1.0.2 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/0e/e1/50dbc513aa74e99eca4c47f2a8206711f0bec436fdddd95eebaf7eaaa1aa/colorhash-1.0.2-py2.py3-none-any.whl\n",
      "Collecting webexteamssdk<1.4.0,>=1.1.1 (from rasa)\n",
      "Collecting apscheduler<3.7,>=3.6 (from rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/f3/34/9ef20ed473c4fd2c3df54ef77a27ae3fc7500b16b192add4720cab8b2c09/APScheduler-3.6.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3<2.0,>=1.12->rasa) (1.16.8)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3<2.0,>=1.12->rasa) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3<2.0,>=1.12->rasa) (0.3.3)\n",
      "Collecting httplib2>=0.9.1 (from oauth2client==4.1.3->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/18/9b/b95a08c373819376bf3f109bdbcff6bd4f69f2340bf708a252380319037a/httplib2-0.17.3-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client==4.1.3->rasa) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client==4.1.3->rasa) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client==4.1.3->rasa) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client==4.1.3->rasa) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.0,>=2.0->rasa) (0.1.7)\n",
      "Collecting websockets<9.0,>=7.0 (from sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/56/01/1f61610f1eb7f9a8e8fdc607a89dd2fae778e6e43290d7e153ebe724adb5/websockets-8.1-cp37-cp37m-win_amd64.whl\n",
      "Collecting httpx==0.9.3 (from sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/d5/17/3f1ec0593b38c82069e745c849114267e980c9fb1254a27ab50f72040251/httpx-0.9.3-py2.py3-none-any.whl\n",
      "Collecting aiofiles>=0.3.0 (from sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/2b/078a9771ae4b67e36b0c2a973df845260833a4eb088b81c84b738509b4c4/aiofiles-0.5.0-py3-none-any.whl\n",
      "Collecting httptools>=0.0.10 (from sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/ae/fb/9a5313e73071eecb0043cb99035647fb0f5f19dd7719abe39da159e39f41/httptools-0.1.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydot<1.5,>=1.4->rasa) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: greenlet>=0.4.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from gevent<1.6,>=1.4->rasa) (0.4.15)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.11.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from gevent<1.6,>=1.4->rasa) (1.12.3)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" (from ruamel.yaml<0.17,>=0.16->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/df/b7/0a84f9a762282314a9df54c56aeec8c2b4f17404ee3d3a05faa76e27e006/ruamel.yaml.clib-0.2.0-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (1.27.2)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.2,>=2.1->rasa) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: pysocks; python_version >= \"3.0\" in c:\\programdata\\anaconda3\\lib\\site-packages (from twilio<6.27,>=6.26->rasa) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpickle<1.5,>=1.3->rasa) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn<0.23,>=0.22->rasa) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: cryptography in c:\\programdata\\anaconda3\\lib\\site-packages (from python-telegram-bot<13.0,>=11.1->rasa) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from python-telegram-bot<13.0,>=11.1->rasa) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-telegram-bot<13.0,>=11.1->rasa) (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-telegram-bot<13.0,>=11.1->rasa) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-telegram-bot<13.0,>=11.1->rasa) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML>=3.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from pykwalify<1.8.0,>=1.7.0->rasa) (5.1.2)\n",
      "Collecting docopt>=0.6.2 (from pykwalify<1.8.0,>=1.7.0->rasa)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.23->rasa) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.23->rasa) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.23->rasa) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<3.3,>=3.2->rasa) (0.15.4)\n",
      "Requirement already satisfied, skipping upgrade: colorama; sys_platform == \"win32\" in c:\\programdata\\anaconda3\\lib\\site-packages (from coloredlogs<11.0,>=10.0->rasa) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: humanfriendly>=4.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from coloredlogs<11.0,>=10.0->rasa) (8.2)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.3,>=3.1->rasa) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.3,>=3.1->rasa) (1.1.0)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<3.7,>=3.6->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/af/bf/bdd154828e7078e89487db8877f65774848a492d50d4c354b857c307872d/yarl-1.4.2-cp37-cp37m-win_amd64.whl\n",
      "Collecting async-timeout<4.0,>=3.0 (from aiohttp<3.7,>=3.6->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
      "Collecting sanic-plugins-framework>=0.9.0 (from sanic-cors<0.11.0,>=0.10.0b1->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/8f/38/4e828a234c64d2f0215f6ad791fa0b49c631b56d3d13269e8eae501fb953/Sanic_Plugins_Framework-0.9.2-py2.py3-none-any.whl\n",
      "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite<0.4,>=0.3->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/9b/1b520e0562ee19b4298dc75e9e27630886e56262753656ef8e46704229ca/python_crfsuite-0.9.7-cp37-cp37m-win_amd64.whl\n",
      "Collecting tabulate (from sklearn-crfsuite<0.4,>=0.3->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/c4/f4/770ae9385990f5a19a91431163d262182d3203662ea2b5739d0fcfc080f1/tabulate-0.8.7-py3-none-any.whl\n",
      "Collecting dnspython<2.0.0,>=1.13.0; extra == \"srv\" (from pymongo[srv,tls]<3.9.0,>=3.8.0->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/d3/3aa0e7213ef72b8585747aa0e271a9523e713813b9a20177ebe1e939deb0/dnspython-1.16.0-py2.py3-none-any.whl\n",
      "Collecting requests-toolbelt (from webexteamssdk<1.4.0,>=1.1.1->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl\n",
      "Collecting tzlocal>=1.2 (from apscheduler<3.7,>=3.6->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/94/d47b0fd5988e6b7059de05720a646a2930920fff247a826f61674d436ba4/tzlocal-2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.17.0,>=1.16.8->boto3<2.0,>=1.12->rasa) (0.15.2)\n",
      "Collecting sniffio==1.* (from httpx==0.9.3->sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/b3/82/4bd4b7d9c0d1dc0fbfbc2a1e00138e7f3ab85bc239358fe9b78aa2ab586d/sniffio-1.1.0-py3-none-any.whl\n",
      "Collecting h2==3.* (from httpx==0.9.3->sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl\n",
      "Collecting hstspreload (from httpx==0.9.3->sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/2c/4c3eb97a40d817611b18d48947e93a7c674c466643f37fa10e104a4d1886/hstspreload-2020.5.13-py3-none-any.whl\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.9.3->sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
      "Collecting h11==0.8.* (from httpx==0.9.3->sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/f9/f3/8e4cf5fa1a3d8bda942a0b1cf92f87815494216fd439f82eb99073141ba0/h11-0.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.11.5->gevent<1.6,>=1.4->rasa) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow<2.2,>=2.1->rasa) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata->jsonpickle<1.5,>=1.3->rasa) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography->python-telegram-bot<13.0,>=11.1->rasa) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyreadline; sys_platform == \"win32\" in c:\\programdata\\anaconda3\\lib\\site-packages (from humanfriendly>=4.7->coloredlogs<11.0,>=10.0->rasa) (2.1)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpx==0.9.3->sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpx==0.9.3->sanic<20.0.0,>=19.12.2->rasa)\n",
      "  Using cached https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in c:\\programdata\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata->jsonpickle<1.5,>=1.3->rasa) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa) (3.1.0)\n",
      "Installing collected packages: typeguard, tensorflow-addons, tqdm, httplib2, oauth2client, requests, mattermostwrapper, sanic-jwt, fbmessenger, rocketchat-API, multidict, websockets, sniffio, hpack, hyperframe, h2, hstspreload, rfc3986, h11, httpx, aiofiles, httptools, sanic, questionary, pydot, yarl, async-timeout, attrs, aiohttp, slackclient, ruamel.yaml.clib, ruamel.yaml, kafka-python, twilio, python-engineio, python-socketio, jsonpickle, scikit-learn, redis, python-telegram-bot, sanic-plugins-framework, sanic-cors, coloredlogs, rasa-sdk, colorclass, packaging, docopt, pykwalify, async-generator, tensorflow-hub, jsonschema, networkx, tensorflow-probability, pika, psycopg2-binary, python-crfsuite, tabulate, sklearn-crfsuite, terminaltables, dnspython, pymongo, colorhash, requests-toolbelt, webexteamssdk, tzlocal, apscheduler, rasa\n",
      "  Found existing installation: tqdm 4.46.0\n",
      "    Uninstalling tqdm-4.46.0:\n",
      "      Successfully uninstalled tqdm-4.46.0\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Found existing installation: attrs 19.2.0\n",
      "    Uninstalling attrs-19.2.0:\n",
      "      Successfully uninstalled attrs-19.2.0\n",
      "  Found existing installation: scikit-learn 0.21.3\n",
      "    Uninstalling scikit-learn-0.21.3:\n",
      "      Successfully uninstalled scikit-learn-0.21.3\n",
      "  Found existing installation: coloredlogs 14.0\n",
      "    Uninstalling coloredlogs-14.0:\n",
      "      Successfully uninstalled coloredlogs-14.0\n",
      "  Found existing installation: packaging 19.2\n",
      "    Uninstalling packaging-19.2:\n",
      "      Successfully uninstalled packaging-19.2\n",
      "  Found existing installation: jsonschema 3.0.2\n",
      "    Uninstalling jsonschema-3.0.2:\n",
      "      Successfully uninstalled jsonschema-3.0.2\n",
      "  Found existing installation: networkx 2.3\n",
      "    Uninstalling networkx-2.3:\n",
      "      Successfully uninstalled networkx-2.3\n",
      "Successfully installed aiofiles-0.5.0 aiohttp-3.6.2 apscheduler-3.6.3 async-generator-1.10 async-timeout-3.0.1 attrs-19.3.0 colorclass-2.2.0 coloredlogs-10.0 colorhash-1.0.2 dnspython-1.16.0 docopt-0.6.2 fbmessenger-6.0.0 h11-0.8.1 h2-3.2.0 hpack-3.0.0 hstspreload-2020.5.13 httplib2-0.17.3 httptools-0.1.1 httpx-0.9.3 hyperframe-5.2.0 jsonpickle-1.4.1 jsonschema-3.2.0 kafka-python-1.4.7 mattermostwrapper-2.2 multidict-4.7.5 networkx-2.4 oauth2client-4.1.3 packaging-19.0 pika-1.1.0 psycopg2-binary-2.8.5 pydot-1.4.1 pykwalify-1.7.0 pymongo-3.8.0 python-crfsuite-0.9.7 python-engineio-3.12.1 python-socketio-4.5.1 python-telegram-bot-12.7 questionary-1.5.2 rasa-1.10.0 rasa-sdk-1.10.1 redis-3.5.1 requests-2.23.0 requests-toolbelt-0.9.1 rfc3986-1.4.0 rocketchat-API-1.3.1 ruamel.yaml-0.16.10 ruamel.yaml.clib-0.2.0 sanic-19.12.2 sanic-cors-0.10.0.post3 sanic-jwt-1.4.1 sanic-plugins-framework-0.9.2 scikit-learn-0.22.2.post1 sklearn-crfsuite-0.3.6 slackclient-2.5.0 sniffio-1.1.0 tabulate-0.8.7 tensorflow-addons-0.9.1 tensorflow-hub-0.8.0 tensorflow-probability-0.9.0 terminaltables-3.1.0 tqdm-4.45.0 twilio-6.26.3 typeguard-2.7.1 tzlocal-2.1 webexteamssdk-1.3 websockets-8.1 yarl-1.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: rasa 1.10.0 has requirement tensorflow-addons<0.8.0,>=0.7.1, but you'll have tensorflow-addons 0.9.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow-addons rasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ujson\n",
      "  Downloading https://files.pythonhosted.org/packages/50/d7/dce3fc97329639bba9c8b3cdadaa51ae2757c9402d4b43ac5feb8b624792/ujson-2.0.3.tar.gz (7.1MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: ujson\n",
      "  Building wheel for ujson (PEP 517): started\n",
      "  Building wheel for ujson (PEP 517): finished with status 'error'\n",
      "  Running setup.py clean for ujson\n",
      "Failed to build ujson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3\\python.exe' 'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' build_wheel 'C:\\Users\\amsarang\\AppData\\Local\\Temp\\tmp1eaut0ng'\n",
      "       cwd: C:\\Users\\amsarang\\AppData\\Local\\Temp\\pip-install-z5mrfszn\\ujson\n",
      "  Complete output (5 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'ujson' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for ujson\n",
      "ERROR: Could not build wheels for ujson which use PEP 517 and cannot be installed directly\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
