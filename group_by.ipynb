{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Max Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Falcon</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Falcon</td>\n",
       "      <td>370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parrot</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parrot</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal  Max Speed\n",
       "0  Falcon      380.0\n",
       "1  Falcon      370.0\n",
       "2  Parrot       24.0\n",
       "3  Parrot       26.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Animal' : ['Falcon', 'Falcon',\n",
    "                              'Parrot', 'Parrot'],\n",
    "                  'Max Speed' : [380., 370., 24., 26.]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max Speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animal</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Falcon</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parrot</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Max Speed\n",
       "Animal           \n",
       "Falcon          2\n",
       "Parrot          2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal = df.groupby('Animal')\n",
    "animal.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrameGroupBy in module pandas.core.groupby.generic object:\n",
      "\n",
      "class DataFrameGroupBy(NDFrameGroupBy)\n",
      " |  DataFrameGroupBy(obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |  \n",
      " |  Class for grouping and aggregating relational data.\n",
      " |  \n",
      " |  See aggregate, transform, and apply functions on this object.\n",
      " |  \n",
      " |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = groupby(obj, ...)\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  obj : pandas object\n",
      " |  axis : int, default 0\n",
      " |  level : int, default None\n",
      " |      Level of MultiIndex\n",
      " |  groupings : list of Grouping objects\n",
      " |      Most users should ignore this\n",
      " |  exclusions : array-like, optional\n",
      " |      List of columns to exclude\n",
      " |  name : string\n",
      " |      Most users should ignore this\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  **Attributes**\n",
      " |  groups : dict\n",
      " |      {group name -> group labels}\n",
      " |  len(grouped) : int\n",
      " |      Number of groups\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  After grouping, see aggregate, apply, and transform functions. Here are\n",
      " |  some other brief notes about usage. When grouping by multiple groups, the\n",
      " |  result index will be a MultiIndex (hierarchical) by default.\n",
      " |  \n",
      " |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n",
      " |  you can write code like:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = obj.groupby(keys, axis=axis)\n",
      " |      for key, group in grouped:\n",
      " |          # do something with the data\n",
      " |  \n",
      " |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n",
      " |  grouped data. So if you group a DataFrame and wish to invoke the std()\n",
      " |  method on each group, you can simply do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).std()\n",
      " |  \n",
      " |  rather than\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).aggregate(np.std)\n",
      " |  \n",
      " |  You can pass arguments to these \"wrapped\" functions, too.\n",
      " |  \n",
      " |  See the online documentation for full exposition on these topics and much\n",
      " |  more\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrameGroupBy\n",
      " |      NDFrameGroupBy\n",
      " |      pandas.core.groupby.groupby.GroupBy\n",
      " |      pandas.core.groupby.groupby._GroupBy\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  agg = aggregate(self, arg, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, arg, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series or scalar\n",
      " |          if DataFrame.agg is called with a single function, returns a Series\n",
      " |          if DataFrame.agg is called with several functions, returns a DataFrame\n",
      " |          if Series.agg is called with single function, returns a scalar\n",
      " |          if Series.agg is called with several functions, returns a Series\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.groupby.apply\n",
      " |      pandas.DataFrame.groupby.transform\n",
      " |      pandas.DataFrame.aggregate\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n",
      " |      ...                    'B': [1, 2, 3, 4],\n",
      " |      ...                    'C': np.random.randn(4)})\n",
      " |      \n",
      " |      >>> df\n",
      " |         A  B         C\n",
      " |      0  1  1  0.362838\n",
      " |      1  1  2  0.227877\n",
      " |      2  2  3  1.267767\n",
      " |      3  2  4 -0.562860\n",
      " |      \n",
      " |      The aggregation is for each column.\n",
      " |      \n",
      " |      >>> df.groupby('A').agg('min')\n",
      " |         B         C\n",
      " |      A\n",
      " |      1  1  0.227877\n",
      " |      2  3 -0.562860\n",
      " |      \n",
      " |      Multiple aggregations\n",
      " |      \n",
      " |      >>> df.groupby('A').agg(['min', 'max'])\n",
      " |          B             C\n",
      " |        min max       min       max\n",
      " |      A\n",
      " |      1   1   2  0.227877  0.362838\n",
      " |      2   3   4 -0.562860  1.267767\n",
      " |      \n",
      " |      Select a column for aggregation\n",
      " |      \n",
      " |      >>> df.groupby('A').B.agg(['min', 'max'])\n",
      " |         min  max\n",
      " |      A\n",
      " |      1    1    2\n",
      " |      2    3    4\n",
      " |      \n",
      " |      Different aggregations per column\n",
      " |      \n",
      " |      >>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})\n",
      " |          B             C\n",
      " |        min max       sum\n",
      " |      A\n",
      " |      1   1   2  0.590716\n",
      " |      2   3   4  0.704907\n",
      " |  \n",
      " |  boxplot = boxplot_frame_groupby(grouped, subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, sharex=False, sharey=True, **kwds)\n",
      " |      Make box plots from DataFrameGroupBy data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      grouped : Grouped DataFrame\n",
      " |      subplots :\n",
      " |          * ``False`` - no subplots will be used\n",
      " |          * ``True`` - create a subplot for each group\n",
      " |      column : column name or list of names, or vector\n",
      " |          Can be any valid input to groupby\n",
      " |      fontsize : int or string\n",
      " |      rot : label rotation angle\n",
      " |      grid : Setting this to True will show the grid\n",
      " |      ax : Matplotlib axis object, default None\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |      layout : tuple (optional)\n",
      " |          (rows, columns) for the layout of the plot\n",
      " |      sharex : bool, default False\n",
      " |          Whether x-axes will be shared among subplots\n",
      " |      \n",
      " |          .. versionadded:: 0.23.1\n",
      " |      sharey : bool, default True\n",
      " |          Whether y-axes will be shared among subplots\n",
      " |      \n",
      " |          .. versionadded:: 0.23.1\n",
      " |      `**kwds` : Keyword Arguments\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          matplotlib's boxplot function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict of key/value = group key/DataFrame.boxplot return value\n",
      " |      or DataFrame.boxplot return value in case subplots=figures=False\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import itertools\n",
      " |      >>> tuples = [t for t in itertools.product(range(1000), range(4))]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n",
      " |      >>> data = np.random.randn(len(index),4)\n",
      " |      >>> df = pd.DataFrame(data, columns=list('ABCD'), index=index)\n",
      " |      >>>\n",
      " |      >>> grouped = df.groupby(level='lvl1')\n",
      " |      >>> boxplot_frame_groupby(grouped)\n",
      " |      >>>\n",
      " |      >>> grouped = df.unstack(level='lvl1').groupby(level=0, axis=1)\n",
      " |      >>> boxplot_frame_groupby(grouped, subplots=False)\n",
      " |  \n",
      " |  count(self)\n",
      " |      Compute count of group, excluding missing values\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return DataFrame with number of distinct observations per group for\n",
      " |      each column.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique: DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',\n",
      " |      ...                           'ham', 'ham'],\n",
      " |      ...                    'value1': [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'value2': list('abbaxy')})\n",
      " |      >>> df\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      1   egg       5      b\n",
      " |      2   egg       5      b\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |      \n",
      " |      >>> df.groupby('id').nunique()\n",
      " |          id  value1  value2\n",
      " |      id\n",
      " |      egg    1       1       1\n",
      " |      ham    1       1       2\n",
      " |      spam   1       2       1\n",
      " |      \n",
      " |      # check for rows with the same id but conflicting values\n",
      " |      >>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  corr\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float\n",
      " |              .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for pearson\n",
      " |          and spearman correlation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith\n",
      " |      Series.corr\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> histogram_intersection = lambda a, b: np.minimum(a, b\n",
      " |      ... ).sum().round(decimals=1)\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs cats\n",
      " |      dogs   1.0  0.3\n",
      " |      cats   0.3  1.0\n",
      " |  \n",
      " |  corrwith\n",
      " |      Compute pairwise correlation between rows or columns of DataFrame\n",
      " |      with rows or columns of Series or DataFrame.  DataFrames are first\n",
      " |      aligned along both axes before computing the correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n",
      " |      drop : boolean, default False\n",
      " |          Drop missing indices from result\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correls : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      -------\n",
      " |      DataFrame.corr\n",
      " |  \n",
      " |  cov\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.cov : Compute covariance with another Series.\n",
      " |      pandas.core.window.EWM.cov: Exponential weighted sample covariance.\n",
      " |      pandas.core.window.Expanding.cov : Expanding sample covariance.\n",
      " |      pandas.core.window.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-1.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <http://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  diff\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a DataFrame element compared with another\n",
      " |      element in the DataFrame (default is the element in the same column\n",
      " |      of the previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |          .. versionadded:: 0.16.1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff: First discrete difference for a Series.\n",
      " |      DataFrame.pct_change: Percent change over given number of periods.\n",
      " |      DataFrame.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a    b     c\n",
      " |      0 NaN  0.0   0.0\n",
      " |      1 NaN -1.0   3.0\n",
      " |      2 NaN -1.0   7.0\n",
      " |      3 NaN -1.0  13.0\n",
      " |      4 NaN  0.0  20.0\n",
      " |      5 NaN  2.0  28.0\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.ftypes : Dtype and sparsity information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  fillna\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                    columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  hist\n",
      " |      Make a histogram of the DataFrame's.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : string or sequence\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : boolean, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : boolean, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : integer or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      **kwds\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      axes : matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          This example draws a histogram based on the length and width of\n",
      " |          some animals, displayed in three bins\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index= ['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Series\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |  \n",
      " |  idxmin\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Series\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |  \n",
      " |  mad\n",
      " |      Return the mean absolute deviation of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  quantile\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default True\n",
      " |          If False, the quantile of datetime and timedelta data will be\n",
      " |          computed as well.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantiles : Series or DataFrame\n",
      " |      \n",
      " |          - If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          - If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |  \n",
      " |  skew\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  take\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      convert : bool, default True\n",
      " |          Whether to convert negative indices into positive ones.\n",
      " |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      " |          The conversions are similar to the behavior of indexing a\n",
      " |          regular Python list.\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |             In the future, negative indices will always be converted.\n",
      " |      \n",
      " |      is_copy : bool, default True\n",
      " |          Whether to return a copy of the original object or not.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                    columns=['name', 'class', 'max_speed'],\n",
      " |      ...                    index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  tshift\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from NDFrameGroupBy:\n",
      " |  \n",
      " |  filter(self, func, dropna=True, *args, **kwargs)\n",
      " |      Return a copy of a DataFrame excluding elements from groups that\n",
      " |      do not satisfy the boolean criterion specified by func.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each subframe. Should return True or False.\n",
      " |      dropna : Drop groups that do not pass the filter. True by default;\n",
      " |          if False, groups that evaluate False are filled with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filtered : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each subframe is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.filter(lambda x: x['B'].mean() > 3.)\n",
      " |           A  B    C\n",
      " |      1  bar  2  5.0\n",
      " |      3  bar  4  1.0\n",
      " |      5  bar  6  9.0\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed DataFrame on each group and\n",
      " |      return a DataFrame having the same indexes as the original object\n",
      " |      filled with the transformed values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each group\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      aggregate, transform\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each group is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      The current implementation imposes three requirements on f:\n",
      " |      \n",
      " |      * f must return a value that either has the same shape as the input\n",
      " |        subframe or can be broadcast to the shape of the input subframe.\n",
      " |        For example, f returns a scalar it will be broadcast to have the\n",
      " |        same shape as the input subframe.\n",
      " |      * if this is a DataFrame, f must support application column-by-column\n",
      " |        in the subframe. If f also supports application to the entire subframe,\n",
      " |        then a fast path is used starting from the second chunk.\n",
      " |      * f must not mutate groups. Mutation is not supported and may\n",
      " |        produce unexpected results.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      # Same shape\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      " |      ...                          'two', 'two'],\n",
      " |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                C         D\n",
      " |      0 -1.154701 -0.577350\n",
      " |      1  0.577350  0.000000\n",
      " |      2  0.577350  1.154701\n",
      " |      3 -1.154701 -1.000000\n",
      " |      4  0.577350 -0.577350\n",
      " |      5  0.577350  1.000000\n",
      " |      \n",
      " |      # Broadcastable\n",
      " |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      " |         C    D\n",
      " |      0  4  6.0\n",
      " |      1  3  8.0\n",
      " |      2  4  6.0\n",
      " |      3  3  8.0\n",
      " |      4  4  6.0\n",
      " |      5  3  8.0\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby.GroupBy:\n",
      " |  \n",
      " |  all(self, skipna=True)\n",
      " |      Returns True if all values in the group are truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  any(self, skipna=True)\n",
      " |      Returns True if any value in the group is truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  backfill(self, limit=None)\n",
      " |      Backward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.backfill\n",
      " |      DataFrame.backfill\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  bfill = backfill(self, limit=None)\n",
      " |  \n",
      " |  cumcount(self, ascending=True)\n",
      " |      Number each item in each group from 0 to the length of that group - 1.\n",
      " |      \n",
      " |      Essentially this is equivalent to\n",
      " |      \n",
      " |      >>> self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from length of group - 1 to 0.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .ngroup : Number the groups themselves.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').cumcount()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    0\n",
      " |      4    1\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').cumcount(ascending=False)\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    1\n",
      " |      4    0\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cummax(self, axis=0, **kwargs)\n",
      " |      Cumulative max for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cummin(self, axis=0, **kwargs)\n",
      " |      Cumulative min for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumprod(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative product for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumsum(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative sum for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  describe(self, **kwargs)\n",
      " |      Generate descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the obersvations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  expanding(self, *args, **kwargs)\n",
      " |      Return an expanding grouper, providing expanding\n",
      " |      functionality per group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ffill = pad(self, limit=None)\n",
      " |  \n",
      " |  first(self, **kwargs)\n",
      " |      Compute first of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows of each group.\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.head(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      " |                            columns=['A', 'B'])\n",
      " |      >>> df.groupby('A', as_index=False).head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |  \n",
      " |  last(self, **kwargs)\n",
      " |      Compute last of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  max(self, **kwargs)\n",
      " |      Compute max of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  mean(self, *args, **kwargs)\n",
      " |      Compute mean of groups, excluding missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series or pandas.DataFrame\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5],\n",
      " |      ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Groupby one column and return the mean of the remaining columns in\n",
      " |      each group.\n",
      " |      \n",
      " |      >>> df.groupby('A').mean()\n",
      " |      >>>\n",
      " |           B         C\n",
      " |      A\n",
      " |      1  3.0  1.333333\n",
      " |      2  4.0  1.500000\n",
      " |      \n",
      " |      Groupby two columns and return the mean of the remaining column.\n",
      " |      \n",
      " |      >>> df.groupby(['A', 'B']).mean()\n",
      " |      >>>\n",
      " |             C\n",
      " |      A B\n",
      " |      1 2.0  2\n",
      " |        4.0  1\n",
      " |      2 3.0  1\n",
      " |        5.0  2\n",
      " |      \n",
      " |      Groupby one column and return the mean of only particular column in\n",
      " |      the group.\n",
      " |      \n",
      " |      >>> df.groupby('A')['B'].mean()\n",
      " |      >>>\n",
      " |      A\n",
      " |      1    3.0\n",
      " |      2    4.0\n",
      " |      Name: B, dtype: float64\n",
      " |  \n",
      " |  median(self, **kwargs)\n",
      " |      Compute median of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  min(self, **kwargs)\n",
      " |      Compute min of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ngroup(self, ascending=True)\n",
      " |      Number each group from 0 to the number of groups - 1.\n",
      " |      \n",
      " |      This is the enumerative complement of cumcount.  Note that the\n",
      " |      numbers given to the groups match the order in which the groups\n",
      " |      would be seen when iterating over the groupby object, not the\n",
      " |      order they are first observed.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.2\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from number of group - 1 to 0.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .cumcount : Number the rows in each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    1\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').ngroup(ascending=False)\n",
      " |      0    1\n",
      " |      1    1\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      4    0\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    3\n",
      " |      4    2\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  nth(self, n, dropna=None)\n",
      " |      Take the nth row from each group if n is an int, or a subset of rows\n",
      " |      if n is a list of ints.\n",
      " |      \n",
      " |      If dropna, will take the nth non-null row, dropna is either\n",
      " |      Truthy (if a Series) or 'all', 'any' (if a DataFrame);\n",
      " |      this is equivalent to calling dropna(how=dropna) before the\n",
      " |      groupby.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int or list of ints\n",
      " |          a single nth value for the row or a list of nth values\n",
      " |      dropna : None or str, optional\n",
      " |          apply the specified dropna operation before counting which row is\n",
      " |          the nth row. Needs to be None, 'any' or 'all'\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      " |      >>> g = df.groupby('A')\n",
      " |      >>> g.nth(0)\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      >>> g.nth(1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth(-1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  4.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth([0, 1])\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      2  5.0\n",
      " |      \n",
      " |      Specifying `dropna` allows count ignoring ``NaN``\n",
      " |      \n",
      " |      >>> g.nth(0, dropna='any')\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      \n",
      " |      NaNs denote group exhausted when using dropna\n",
      " |      \n",
      " |      >>> g.nth(3, dropna='any')\n",
      " |          B\n",
      " |      A\n",
      " |      1 NaN\n",
      " |      2 NaN\n",
      " |      \n",
      " |      Specifying `as_index=False` in `groupby` keeps the original index.\n",
      " |      \n",
      " |      >>> df.groupby('A', as_index=False).nth(1)\n",
      " |         A    B\n",
      " |      1  1  2.0\n",
      " |      4  2  5.0\n",
      " |  \n",
      " |  ohlc(self)\n",
      " |      Compute sum of values, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  pad(self, limit=None)\n",
      " |      Forward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pad\n",
      " |      DataFrame.pad\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, axis=0)\n",
      " |      Calculate pct_change of each value to previous entry in group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  prod(self, **kwargs)\n",
      " |      Compute prod of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  rank(self, method='average', ascending=True, na_option='keep', pct=False, axis=0)\n",
      " |      Provides the rank of values within each group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      na_option :  {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      pct : boolean, default False\n",
      " |          Compute percentage rank of data within each group\n",
      " |      axis : int, default 0\n",
      " |          The axis of the object over which to compute the rank.\n",
      " |      \n",
      " |      Returns\n",
      " |      -----\n",
      " |      DataFrame with ranking of values within each group\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  resample(self, rule, *args, **kwargs)\n",
      " |      Provide resampling when using a TimeGrouper.\n",
      " |      \n",
      " |      Given a grouper, the function resamples it according to a string\n",
      " |      \"string\" -> \"frequency\".\n",
      " |      \n",
      " |      See the :ref:`frequency aliases <timeseries.offset_aliases>`\n",
      " |      documentation for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : str or DateOffset\n",
      " |          The offset string or object representing target grouper conversion.\n",
      " |      *args, **kwargs\n",
      " |          Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n",
      " |          `on`, and other arguments of `TimeGrouper`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Grouper\n",
      " |          Return a new grouper with our resampler appended.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Grouper : Specify a frequency to resample with when\n",
      " |          grouping by a key.\n",
      " |      DatetimeIndex.resample : Frequency conversion and resampling of\n",
      " |          time series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> df = pd.DataFrame(data=4 * [range(2)],\n",
      " |      ...                   index=idx,\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.iloc[2, 0] = 5\n",
      " |      >>> df\n",
      " |                          a  b\n",
      " |      2000-01-01 00:00:00  0  1\n",
      " |      2000-01-01 00:01:00  0  1\n",
      " |      2000-01-01 00:02:00  5  1\n",
      " |      2000-01-01 00:03:00  0  1\n",
      " |      \n",
      " |      Downsample the DataFrame into 3 minute bins and sum the values of\n",
      " |      the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  2\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('30S').sum()\n",
      " |                          a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:00:30  0  0\n",
      " |          2000-01-01 00:01:00  0  1\n",
      " |          2000-01-01 00:01:30  0  0\n",
      " |          2000-01-01 00:02:00  0  0\n",
      " |          2000-01-01 00:02:30  0  0\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:02:00  5  1\n",
      " |      \n",
      " |      Resample by month. Values are assigned to the month of the period.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('M').sum()\n",
      " |                  a  b\n",
      " |      a\n",
      " |      0   2000-01-31  0  3\n",
      " |      5   2000-01-31  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   1999-12-31 23:57:00  0  1\n",
      " |          2000-01-01 00:00:00  0  2\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and close the right side of\n",
      " |      the bin interval, but label each bin using the right edge instead of\n",
      " |      the left.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:03:00  0  2\n",
      " |      5   2000-01-01 00:03:00  5  1\n",
      " |      \n",
      " |      Add an offset of twenty seconds.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', loffset='20s').sum()\n",
      " |                             a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:20  0  2\n",
      " |          2000-01-01 00:03:20  0  1\n",
      " |      5   2000-01-01 00:00:20  5  1\n",
      " |  \n",
      " |  rolling(self, *args, **kwargs)\n",
      " |      Return a rolling grouper, providing rolling functionality per group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sem(self, ddof=1)\n",
      " |      Compute standard error of the mean of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0, fill_value=None)\n",
      " |      Shift each group by periods observations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : integer, default 1\n",
      " |          number of periods to shift\n",
      " |      freq : frequency string\n",
      " |      axis : axis to shift, default 0\n",
      " |      fill_value : optional\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  size(self)\n",
      " |      Compute group sizes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  std(self, ddof=1, *args, **kwargs)\n",
      " |      Compute standard deviation of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sum(self, **kwargs)\n",
      " |      Compute sum of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows of each group.\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.tail(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      " |                            columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').tail(1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      2  b  1\n",
      " |  \n",
      " |  var(self, ddof=1, *args, **kwargs)\n",
      " |      Compute variance of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby._GroupBy:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __init__(self, obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Groupby iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Generator yielding sequence of (name, subsetted object)\n",
      " |      for each group\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by unicode(obj) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  apply(self, func, *args, **kwargs)\n",
      " |      Apply function `func`  group-wise and combine the results together.\n",
      " |      \n",
      " |      The function passed to `apply` must take a dataframe as its first\n",
      " |      argument and return a DataFrame, Series or scalar. `apply` will\n",
      " |      then take care of combining the results back together into a single\n",
      " |      dataframe or series. `apply` is therefore a highly flexible\n",
      " |      grouping method.\n",
      " |      \n",
      " |      While `apply` is a very flexible method, its downside is that\n",
      " |      using it can be quite a bit slower than using more specific methods\n",
      " |      like `agg` or `transform`. Pandas offers a wide range of method that will\n",
      " |      be much faster than using `apply` for their specific purposes, so try to\n",
      " |      use them before reaching for `apply`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          A callable that takes a dataframe as its first argument, and\n",
      " |          returns a dataframe, a series or a scalar. In addition the\n",
      " |          callable may take positional and keyword arguments.\n",
      " |      args, kwargs : tuple and dict\n",
      " |          Optional positional and keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pipe : Apply function to the full GroupBy object instead of to each\n",
      " |          group.\n",
      " |      aggregate : Apply aggregate function to the GroupBy object.\n",
      " |      transform : Apply function column-by-column to the GroupBy object.\n",
      " |      Series.apply : Apply a function to a Series.\n",
      " |      DataFrame.apply : Apply a function to each row or column of a DataFrame.\n",
      " |  \n",
      " |  get_group(self, name, obj=None)\n",
      " |      Constructs NDFrame from group with provided name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object\n",
      " |          the name of the group to get as a DataFrame\n",
      " |      obj : NDFrame, default None\n",
      " |          the NDFrame to take the DataFrame out of.  If\n",
      " |          it is None, the object groupby was called on will\n",
      " |          be used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      group : same type as obj\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply a function `func` with arguments to this GroupBy object and return\n",
      " |      the function's result.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Use `.pipe` when you want to improve readability by chaining together\n",
      " |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      " |      Instead of writing\n",
      " |      \n",
      " |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.groupby('group')\n",
      " |      ...    .pipe(f)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(h, arg2=b, arg3=c))\n",
      " |      \n",
      " |      which is much more readable.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable or tuple of (callable, string)\n",
      " |          Function to apply to this GroupBy object or, alternatively,\n",
      " |          a `(callable, data_keyword)` tuple where `data_keyword` is a\n",
      " |          string indicating the keyword of `callable` that expects the\n",
      " |          GroupBy object.\n",
      " |      args : iterable, optional\n",
      " |             positional arguments passed into `func`.\n",
      " |      kwargs : dict, optional\n",
      " |               a dictionary of keyword arguments passed into `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of `func`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.pipe : Apply a function with arguments to a series.\n",
      " |      pandas.DataFrame.pipe: Apply a function with arguments to a dataframe.\n",
      " |      apply : Apply function to each group instead of to the\n",
      " |          full GroupBy object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See more `here\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html#piping-function-calls>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      1  b  2\n",
      " |      2  a  3\n",
      " |      3  b  4\n",
      " |      \n",
      " |      To get the difference between each groups maximum and minimum value in one\n",
      " |      pass, you can do\n",
      " |      \n",
      " |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      " |         B\n",
      " |      A\n",
      " |      a  2\n",
      " |      b  2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.groupby.groupby._GroupBy:\n",
      " |  \n",
      " |  groups\n",
      " |      Dict {group name -> group labels}.\n",
      " |  \n",
      " |  indices\n",
      " |      Dict {group name -> group indices}.\n",
      " |  \n",
      " |  ngroups\n",
      " |  \n",
      " |  plot\n",
      " |      Class implementing the .plot attribute for groupby objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  ndim\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Falcon': Int64Index([0, 1], dtype='int64'),\n",
       " 'Parrot': Int64Index([2, 3], dtype='int64')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Falcon', 'Parrot'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([Int64Index([0, 1], dtype='int64'), Int64Index([2, 3], dtype='int64')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal.groups.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falcon  ->     Animal  Max Speed\n",
      "0  Falcon      380.0\n",
      "1  Falcon      370.0\n",
      "Parrot  ->     Animal  Max Speed\n",
      "2  Parrot       24.0\n",
      "3  Parrot       26.0\n"
     ]
    }
   ],
   "source": [
    "for key, group in animal:\n",
    "    print(key,\" -> \" ,group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Animal  Max Speed\n",
      "0  Falcon      380.0\n",
      "1  Falcon      370.0\n",
      "group['Animal'] =  0    Falcon\n",
      "1    Falcon\n",
      "Name: Animal, dtype: object \n",
      "\n",
      "group['Max Speed'] =  0    380.0\n",
      "1    370.0\n",
      "Name: Max Speed, dtype: float64 \n",
      "\n",
      "Type =  <class 'pandas.core.frame.DataFrame'>\n",
      "   Animal  Max Speed\n",
      "2  Parrot       24.0\n",
      "3  Parrot       26.0\n",
      "group['Animal'] =  2    Parrot\n",
      "3    Parrot\n",
      "Name: Animal, dtype: object \n",
      "\n",
      "group['Max Speed'] =  2    24.0\n",
      "3    26.0\n",
      "Name: Max Speed, dtype: float64 \n",
      "\n",
      "Type =  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "group1 = []\n",
    "for key, group in animal:\n",
    "    print(group)\n",
    "    print(\"group['Animal'] = \",group[\"Animal\"],\"\\n\")\n",
    "    print(\"group['Max Speed'] = \",group[\"Max Speed\"],\"\\n\")\n",
    "    print(\"Type = \", type(group))\n",
    "    group1.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   Animal  Max Speed\n",
       " 0  Falcon      380.0\n",
       " 1  Falcon      370.0,    Animal  Max Speed\n",
       " 2  Parrot       24.0\n",
       " 3  Parrot       26.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(group1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': [1, 1, 2, 2],\n",
    "                 'B': [1, 2, 3, 4],\n",
    "                 'C': np.random.randn(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.914330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.396580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.143018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.506791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B         C\n",
       "0  1  1 -0.914330\n",
       "1  1  2 -0.396580\n",
       "2  2  3  0.143018\n",
       "3  2  4 -0.506791"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.914330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.506791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B         C\n",
       "A             \n",
       "1  1 -0.914330\n",
       "2  3 -0.506791"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby('A').agg('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  C\n",
       "A      \n",
       "1  2  2\n",
       "2  2  2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby('A').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">B</th>\n",
       "      <th colspan=\"2\" halign=\"left\">C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.914330</td>\n",
       "      <td>-0.396580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.506791</td>\n",
       "      <td>0.143018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    B             C          \n",
       "  min max       min       max\n",
       "A                            \n",
       "1   1   2 -0.914330 -0.396580\n",
       "2   3   4 -0.506791  0.143018"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby('A').agg(['min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max  sum\n",
       "A          \n",
       "1    2    3\n",
       "2    4    7"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(\"A\").B.agg(['max', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.310910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.363772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    B             C\n",
       "  min max       sum\n",
       "A                  \n",
       "1   1   2 -1.310910\n",
       "2   3   4 -0.363772"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby('A').agg({'B':['min','max'], 'C':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (5, 0),\n",
       " (5, 1),\n",
       " (5, 2),\n",
       " (5, 3),\n",
       " (6, 0),\n",
       " (6, 1),\n",
       " (6, 2),\n",
       " (6, 3),\n",
       " (7, 0),\n",
       " (7, 1),\n",
       " (7, 2),\n",
       " (7, 3),\n",
       " (8, 0),\n",
       " (8, 1),\n",
       " (8, 2),\n",
       " (8, 3),\n",
       " (9, 0),\n",
       " (9, 1),\n",
       " (9, 2),\n",
       " (9, 3),\n",
       " (10, 0),\n",
       " (10, 1),\n",
       " (10, 2),\n",
       " (10, 3),\n",
       " (11, 0),\n",
       " (11, 1),\n",
       " (11, 2),\n",
       " (11, 3),\n",
       " (12, 0),\n",
       " (12, 1),\n",
       " (12, 2),\n",
       " (12, 3),\n",
       " (13, 0),\n",
       " (13, 1),\n",
       " (13, 2),\n",
       " (13, 3),\n",
       " (14, 0),\n",
       " (14, 1),\n",
       " (14, 2),\n",
       " (14, 3),\n",
       " (15, 0),\n",
       " (15, 1),\n",
       " (15, 2),\n",
       " (15, 3),\n",
       " (16, 0),\n",
       " (16, 1),\n",
       " (16, 2),\n",
       " (16, 3),\n",
       " (17, 0),\n",
       " (17, 1),\n",
       " (17, 2),\n",
       " (17, 3),\n",
       " (18, 0),\n",
       " (18, 1),\n",
       " (18, 2),\n",
       " (18, 3),\n",
       " (19, 0),\n",
       " (19, 1),\n",
       " (19, 2),\n",
       " (19, 3),\n",
       " (20, 0),\n",
       " (20, 1),\n",
       " (20, 2),\n",
       " (20, 3),\n",
       " (21, 0),\n",
       " (21, 1),\n",
       " (21, 2),\n",
       " (21, 3),\n",
       " (22, 0),\n",
       " (22, 1),\n",
       " (22, 2),\n",
       " (22, 3),\n",
       " (23, 0),\n",
       " (23, 1),\n",
       " (23, 2),\n",
       " (23, 3),\n",
       " (24, 0),\n",
       " (24, 1),\n",
       " (24, 2),\n",
       " (24, 3),\n",
       " (25, 0),\n",
       " (25, 1),\n",
       " (25, 2),\n",
       " (25, 3),\n",
       " (26, 0),\n",
       " (26, 1),\n",
       " (26, 2),\n",
       " (26, 3),\n",
       " (27, 0),\n",
       " (27, 1),\n",
       " (27, 2),\n",
       " (27, 3),\n",
       " (28, 0),\n",
       " (28, 1),\n",
       " (28, 2),\n",
       " (28, 3),\n",
       " (29, 0),\n",
       " (29, 1),\n",
       " (29, 2),\n",
       " (29, 3),\n",
       " (30, 0),\n",
       " (30, 1),\n",
       " (30, 2),\n",
       " (30, 3),\n",
       " (31, 0),\n",
       " (31, 1),\n",
       " (31, 2),\n",
       " (31, 3),\n",
       " (32, 0),\n",
       " (32, 1),\n",
       " (32, 2),\n",
       " (32, 3),\n",
       " (33, 0),\n",
       " (33, 1),\n",
       " (33, 2),\n",
       " (33, 3),\n",
       " (34, 0),\n",
       " (34, 1),\n",
       " (34, 2),\n",
       " (34, 3),\n",
       " (35, 0),\n",
       " (35, 1),\n",
       " (35, 2),\n",
       " (35, 3),\n",
       " (36, 0),\n",
       " (36, 1),\n",
       " (36, 2),\n",
       " (36, 3),\n",
       " (37, 0),\n",
       " (37, 1),\n",
       " (37, 2),\n",
       " (37, 3),\n",
       " (38, 0),\n",
       " (38, 1),\n",
       " (38, 2),\n",
       " (38, 3),\n",
       " (39, 0),\n",
       " (39, 1),\n",
       " (39, 2),\n",
       " (39, 3),\n",
       " (40, 0),\n",
       " (40, 1),\n",
       " (40, 2),\n",
       " (40, 3),\n",
       " (41, 0),\n",
       " (41, 1),\n",
       " (41, 2),\n",
       " (41, 3),\n",
       " (42, 0),\n",
       " (42, 1),\n",
       " (42, 2),\n",
       " (42, 3),\n",
       " (43, 0),\n",
       " (43, 1),\n",
       " (43, 2),\n",
       " (43, 3),\n",
       " (44, 0),\n",
       " (44, 1),\n",
       " (44, 2),\n",
       " (44, 3),\n",
       " (45, 0),\n",
       " (45, 1),\n",
       " (45, 2),\n",
       " (45, 3),\n",
       " (46, 0),\n",
       " (46, 1),\n",
       " (46, 2),\n",
       " (46, 3),\n",
       " (47, 0),\n",
       " (47, 1),\n",
       " (47, 2),\n",
       " (47, 3),\n",
       " (48, 0),\n",
       " (48, 1),\n",
       " (48, 2),\n",
       " (48, 3),\n",
       " (49, 0),\n",
       " (49, 1),\n",
       " (49, 2),\n",
       " (49, 3),\n",
       " (50, 0),\n",
       " (50, 1),\n",
       " (50, 2),\n",
       " (50, 3),\n",
       " (51, 0),\n",
       " (51, 1),\n",
       " (51, 2),\n",
       " (51, 3),\n",
       " (52, 0),\n",
       " (52, 1),\n",
       " (52, 2),\n",
       " (52, 3),\n",
       " (53, 0),\n",
       " (53, 1),\n",
       " (53, 2),\n",
       " (53, 3),\n",
       " (54, 0),\n",
       " (54, 1),\n",
       " (54, 2),\n",
       " (54, 3),\n",
       " (55, 0),\n",
       " (55, 1),\n",
       " (55, 2),\n",
       " (55, 3),\n",
       " (56, 0),\n",
       " (56, 1),\n",
       " (56, 2),\n",
       " (56, 3),\n",
       " (57, 0),\n",
       " (57, 1),\n",
       " (57, 2),\n",
       " (57, 3),\n",
       " (58, 0),\n",
       " (58, 1),\n",
       " (58, 2),\n",
       " (58, 3),\n",
       " (59, 0),\n",
       " (59, 1),\n",
       " (59, 2),\n",
       " (59, 3),\n",
       " (60, 0),\n",
       " (60, 1),\n",
       " (60, 2),\n",
       " (60, 3),\n",
       " (61, 0),\n",
       " (61, 1),\n",
       " (61, 2),\n",
       " (61, 3),\n",
       " (62, 0),\n",
       " (62, 1),\n",
       " (62, 2),\n",
       " (62, 3),\n",
       " (63, 0),\n",
       " (63, 1),\n",
       " (63, 2),\n",
       " (63, 3),\n",
       " (64, 0),\n",
       " (64, 1),\n",
       " (64, 2),\n",
       " (64, 3),\n",
       " (65, 0),\n",
       " (65, 1),\n",
       " (65, 2),\n",
       " (65, 3),\n",
       " (66, 0),\n",
       " (66, 1),\n",
       " (66, 2),\n",
       " (66, 3),\n",
       " (67, 0),\n",
       " (67, 1),\n",
       " (67, 2),\n",
       " (67, 3),\n",
       " (68, 0),\n",
       " (68, 1),\n",
       " (68, 2),\n",
       " (68, 3),\n",
       " (69, 0),\n",
       " (69, 1),\n",
       " (69, 2),\n",
       " (69, 3),\n",
       " (70, 0),\n",
       " (70, 1),\n",
       " (70, 2),\n",
       " (70, 3),\n",
       " (71, 0),\n",
       " (71, 1),\n",
       " (71, 2),\n",
       " (71, 3),\n",
       " (72, 0),\n",
       " (72, 1),\n",
       " (72, 2),\n",
       " (72, 3),\n",
       " (73, 0),\n",
       " (73, 1),\n",
       " (73, 2),\n",
       " (73, 3),\n",
       " (74, 0),\n",
       " (74, 1),\n",
       " (74, 2),\n",
       " (74, 3),\n",
       " (75, 0),\n",
       " (75, 1),\n",
       " (75, 2),\n",
       " (75, 3),\n",
       " (76, 0),\n",
       " (76, 1),\n",
       " (76, 2),\n",
       " (76, 3),\n",
       " (77, 0),\n",
       " (77, 1),\n",
       " (77, 2),\n",
       " (77, 3),\n",
       " (78, 0),\n",
       " (78, 1),\n",
       " (78, 2),\n",
       " (78, 3),\n",
       " (79, 0),\n",
       " (79, 1),\n",
       " (79, 2),\n",
       " (79, 3),\n",
       " (80, 0),\n",
       " (80, 1),\n",
       " (80, 2),\n",
       " (80, 3),\n",
       " (81, 0),\n",
       " (81, 1),\n",
       " (81, 2),\n",
       " (81, 3),\n",
       " (82, 0),\n",
       " (82, 1),\n",
       " (82, 2),\n",
       " (82, 3),\n",
       " (83, 0),\n",
       " (83, 1),\n",
       " (83, 2),\n",
       " (83, 3),\n",
       " (84, 0),\n",
       " (84, 1),\n",
       " (84, 2),\n",
       " (84, 3),\n",
       " (85, 0),\n",
       " (85, 1),\n",
       " (85, 2),\n",
       " (85, 3),\n",
       " (86, 0),\n",
       " (86, 1),\n",
       " (86, 2),\n",
       " (86, 3),\n",
       " (87, 0),\n",
       " (87, 1),\n",
       " (87, 2),\n",
       " (87, 3),\n",
       " (88, 0),\n",
       " (88, 1),\n",
       " (88, 2),\n",
       " (88, 3),\n",
       " (89, 0),\n",
       " (89, 1),\n",
       " (89, 2),\n",
       " (89, 3),\n",
       " (90, 0),\n",
       " (90, 1),\n",
       " (90, 2),\n",
       " (90, 3),\n",
       " (91, 0),\n",
       " (91, 1),\n",
       " (91, 2),\n",
       " (91, 3),\n",
       " (92, 0),\n",
       " (92, 1),\n",
       " (92, 2),\n",
       " (92, 3),\n",
       " (93, 0),\n",
       " (93, 1),\n",
       " (93, 2),\n",
       " (93, 3),\n",
       " (94, 0),\n",
       " (94, 1),\n",
       " (94, 2),\n",
       " (94, 3),\n",
       " (95, 0),\n",
       " (95, 1),\n",
       " (95, 2),\n",
       " (95, 3),\n",
       " (96, 0),\n",
       " (96, 1),\n",
       " (96, 2),\n",
       " (96, 3),\n",
       " (97, 0),\n",
       " (97, 1),\n",
       " (97, 2),\n",
       " (97, 3),\n",
       " (98, 0),\n",
       " (98, 1),\n",
       " (98, 2),\n",
       " (98, 3),\n",
       " (99, 0),\n",
       " (99, 1),\n",
       " (99, 2),\n",
       " (99, 3),\n",
       " (100, 0),\n",
       " (100, 1),\n",
       " (100, 2),\n",
       " (100, 3),\n",
       " (101, 0),\n",
       " (101, 1),\n",
       " (101, 2),\n",
       " (101, 3),\n",
       " (102, 0),\n",
       " (102, 1),\n",
       " (102, 2),\n",
       " (102, 3),\n",
       " (103, 0),\n",
       " (103, 1),\n",
       " (103, 2),\n",
       " (103, 3),\n",
       " (104, 0),\n",
       " (104, 1),\n",
       " (104, 2),\n",
       " (104, 3),\n",
       " (105, 0),\n",
       " (105, 1),\n",
       " (105, 2),\n",
       " (105, 3),\n",
       " (106, 0),\n",
       " (106, 1),\n",
       " (106, 2),\n",
       " (106, 3),\n",
       " (107, 0),\n",
       " (107, 1),\n",
       " (107, 2),\n",
       " (107, 3),\n",
       " (108, 0),\n",
       " (108, 1),\n",
       " (108, 2),\n",
       " (108, 3),\n",
       " (109, 0),\n",
       " (109, 1),\n",
       " (109, 2),\n",
       " (109, 3),\n",
       " (110, 0),\n",
       " (110, 1),\n",
       " (110, 2),\n",
       " (110, 3),\n",
       " (111, 0),\n",
       " (111, 1),\n",
       " (111, 2),\n",
       " (111, 3),\n",
       " (112, 0),\n",
       " (112, 1),\n",
       " (112, 2),\n",
       " (112, 3),\n",
       " (113, 0),\n",
       " (113, 1),\n",
       " (113, 2),\n",
       " (113, 3),\n",
       " (114, 0),\n",
       " (114, 1),\n",
       " (114, 2),\n",
       " (114, 3),\n",
       " (115, 0),\n",
       " (115, 1),\n",
       " (115, 2),\n",
       " (115, 3),\n",
       " (116, 0),\n",
       " (116, 1),\n",
       " (116, 2),\n",
       " (116, 3),\n",
       " (117, 0),\n",
       " (117, 1),\n",
       " (117, 2),\n",
       " (117, 3),\n",
       " (118, 0),\n",
       " (118, 1),\n",
       " (118, 2),\n",
       " (118, 3),\n",
       " (119, 0),\n",
       " (119, 1),\n",
       " (119, 2),\n",
       " (119, 3),\n",
       " (120, 0),\n",
       " (120, 1),\n",
       " (120, 2),\n",
       " (120, 3),\n",
       " (121, 0),\n",
       " (121, 1),\n",
       " (121, 2),\n",
       " (121, 3),\n",
       " (122, 0),\n",
       " (122, 1),\n",
       " (122, 2),\n",
       " (122, 3),\n",
       " (123, 0),\n",
       " (123, 1),\n",
       " (123, 2),\n",
       " (123, 3),\n",
       " (124, 0),\n",
       " (124, 1),\n",
       " (124, 2),\n",
       " (124, 3),\n",
       " (125, 0),\n",
       " (125, 1),\n",
       " (125, 2),\n",
       " (125, 3),\n",
       " (126, 0),\n",
       " (126, 1),\n",
       " (126, 2),\n",
       " (126, 3),\n",
       " (127, 0),\n",
       " (127, 1),\n",
       " (127, 2),\n",
       " (127, 3),\n",
       " (128, 0),\n",
       " (128, 1),\n",
       " (128, 2),\n",
       " (128, 3),\n",
       " (129, 0),\n",
       " (129, 1),\n",
       " (129, 2),\n",
       " (129, 3),\n",
       " (130, 0),\n",
       " (130, 1),\n",
       " (130, 2),\n",
       " (130, 3),\n",
       " (131, 0),\n",
       " (131, 1),\n",
       " (131, 2),\n",
       " (131, 3),\n",
       " (132, 0),\n",
       " (132, 1),\n",
       " (132, 2),\n",
       " (132, 3),\n",
       " (133, 0),\n",
       " (133, 1),\n",
       " (133, 2),\n",
       " (133, 3),\n",
       " (134, 0),\n",
       " (134, 1),\n",
       " (134, 2),\n",
       " (134, 3),\n",
       " (135, 0),\n",
       " (135, 1),\n",
       " (135, 2),\n",
       " (135, 3),\n",
       " (136, 0),\n",
       " (136, 1),\n",
       " (136, 2),\n",
       " (136, 3),\n",
       " (137, 0),\n",
       " (137, 1),\n",
       " (137, 2),\n",
       " (137, 3),\n",
       " (138, 0),\n",
       " (138, 1),\n",
       " (138, 2),\n",
       " (138, 3),\n",
       " (139, 0),\n",
       " (139, 1),\n",
       " (139, 2),\n",
       " (139, 3),\n",
       " (140, 0),\n",
       " (140, 1),\n",
       " (140, 2),\n",
       " (140, 3),\n",
       " (141, 0),\n",
       " (141, 1),\n",
       " (141, 2),\n",
       " (141, 3),\n",
       " (142, 0),\n",
       " (142, 1),\n",
       " (142, 2),\n",
       " (142, 3),\n",
       " (143, 0),\n",
       " (143, 1),\n",
       " (143, 2),\n",
       " (143, 3),\n",
       " (144, 0),\n",
       " (144, 1),\n",
       " (144, 2),\n",
       " (144, 3),\n",
       " (145, 0),\n",
       " (145, 1),\n",
       " (145, 2),\n",
       " (145, 3),\n",
       " (146, 0),\n",
       " (146, 1),\n",
       " (146, 2),\n",
       " (146, 3),\n",
       " (147, 0),\n",
       " (147, 1),\n",
       " (147, 2),\n",
       " (147, 3),\n",
       " (148, 0),\n",
       " (148, 1),\n",
       " (148, 2),\n",
       " (148, 3),\n",
       " (149, 0),\n",
       " (149, 1),\n",
       " (149, 2),\n",
       " (149, 3),\n",
       " (150, 0),\n",
       " (150, 1),\n",
       " (150, 2),\n",
       " (150, 3),\n",
       " (151, 0),\n",
       " (151, 1),\n",
       " (151, 2),\n",
       " (151, 3),\n",
       " (152, 0),\n",
       " (152, 1),\n",
       " (152, 2),\n",
       " (152, 3),\n",
       " (153, 0),\n",
       " (153, 1),\n",
       " (153, 2),\n",
       " (153, 3),\n",
       " (154, 0),\n",
       " (154, 1),\n",
       " (154, 2),\n",
       " (154, 3),\n",
       " (155, 0),\n",
       " (155, 1),\n",
       " (155, 2),\n",
       " (155, 3),\n",
       " (156, 0),\n",
       " (156, 1),\n",
       " (156, 2),\n",
       " (156, 3),\n",
       " (157, 0),\n",
       " (157, 1),\n",
       " (157, 2),\n",
       " (157, 3),\n",
       " (158, 0),\n",
       " (158, 1),\n",
       " (158, 2),\n",
       " (158, 3),\n",
       " (159, 0),\n",
       " (159, 1),\n",
       " (159, 2),\n",
       " (159, 3),\n",
       " (160, 0),\n",
       " (160, 1),\n",
       " (160, 2),\n",
       " (160, 3),\n",
       " (161, 0),\n",
       " (161, 1),\n",
       " (161, 2),\n",
       " (161, 3),\n",
       " (162, 0),\n",
       " (162, 1),\n",
       " (162, 2),\n",
       " (162, 3),\n",
       " (163, 0),\n",
       " (163, 1),\n",
       " (163, 2),\n",
       " (163, 3),\n",
       " (164, 0),\n",
       " (164, 1),\n",
       " (164, 2),\n",
       " (164, 3),\n",
       " (165, 0),\n",
       " (165, 1),\n",
       " (165, 2),\n",
       " (165, 3),\n",
       " (166, 0),\n",
       " (166, 1),\n",
       " (166, 2),\n",
       " (166, 3),\n",
       " (167, 0),\n",
       " (167, 1),\n",
       " (167, 2),\n",
       " (167, 3),\n",
       " (168, 0),\n",
       " (168, 1),\n",
       " (168, 2),\n",
       " (168, 3),\n",
       " (169, 0),\n",
       " (169, 1),\n",
       " (169, 2),\n",
       " (169, 3),\n",
       " (170, 0),\n",
       " (170, 1),\n",
       " (170, 2),\n",
       " (170, 3),\n",
       " (171, 0),\n",
       " (171, 1),\n",
       " (171, 2),\n",
       " (171, 3),\n",
       " (172, 0),\n",
       " (172, 1),\n",
       " (172, 2),\n",
       " (172, 3),\n",
       " (173, 0),\n",
       " (173, 1),\n",
       " (173, 2),\n",
       " (173, 3),\n",
       " (174, 0),\n",
       " (174, 1),\n",
       " (174, 2),\n",
       " (174, 3),\n",
       " (175, 0),\n",
       " (175, 1),\n",
       " (175, 2),\n",
       " (175, 3),\n",
       " (176, 0),\n",
       " (176, 1),\n",
       " (176, 2),\n",
       " (176, 3),\n",
       " (177, 0),\n",
       " (177, 1),\n",
       " (177, 2),\n",
       " (177, 3),\n",
       " (178, 0),\n",
       " (178, 1),\n",
       " (178, 2),\n",
       " (178, 3),\n",
       " (179, 0),\n",
       " (179, 1),\n",
       " (179, 2),\n",
       " (179, 3),\n",
       " (180, 0),\n",
       " (180, 1),\n",
       " (180, 2),\n",
       " (180, 3),\n",
       " (181, 0),\n",
       " (181, 1),\n",
       " (181, 2),\n",
       " (181, 3),\n",
       " (182, 0),\n",
       " (182, 1),\n",
       " (182, 2),\n",
       " (182, 3),\n",
       " (183, 0),\n",
       " (183, 1),\n",
       " (183, 2),\n",
       " (183, 3),\n",
       " (184, 0),\n",
       " (184, 1),\n",
       " (184, 2),\n",
       " (184, 3),\n",
       " (185, 0),\n",
       " (185, 1),\n",
       " (185, 2),\n",
       " (185, 3),\n",
       " (186, 0),\n",
       " (186, 1),\n",
       " (186, 2),\n",
       " (186, 3),\n",
       " (187, 0),\n",
       " (187, 1),\n",
       " (187, 2),\n",
       " (187, 3),\n",
       " (188, 0),\n",
       " (188, 1),\n",
       " (188, 2),\n",
       " (188, 3),\n",
       " (189, 0),\n",
       " (189, 1),\n",
       " (189, 2),\n",
       " (189, 3),\n",
       " (190, 0),\n",
       " (190, 1),\n",
       " (190, 2),\n",
       " (190, 3),\n",
       " (191, 0),\n",
       " (191, 1),\n",
       " (191, 2),\n",
       " (191, 3),\n",
       " (192, 0),\n",
       " (192, 1),\n",
       " (192, 2),\n",
       " (192, 3),\n",
       " (193, 0),\n",
       " (193, 1),\n",
       " (193, 2),\n",
       " (193, 3),\n",
       " (194, 0),\n",
       " (194, 1),\n",
       " (194, 2),\n",
       " (194, 3),\n",
       " (195, 0),\n",
       " (195, 1),\n",
       " (195, 2),\n",
       " (195, 3),\n",
       " (196, 0),\n",
       " (196, 1),\n",
       " (196, 2),\n",
       " (196, 3),\n",
       " (197, 0),\n",
       " (197, 1),\n",
       " (197, 2),\n",
       " (197, 3),\n",
       " (198, 0),\n",
       " (198, 1),\n",
       " (198, 2),\n",
       " (198, 3),\n",
       " (199, 0),\n",
       " (199, 1),\n",
       " (199, 2),\n",
       " (199, 3),\n",
       " (200, 0),\n",
       " (200, 1),\n",
       " (200, 2),\n",
       " (200, 3),\n",
       " (201, 0),\n",
       " (201, 1),\n",
       " (201, 2),\n",
       " (201, 3),\n",
       " (202, 0),\n",
       " (202, 1),\n",
       " (202, 2),\n",
       " (202, 3),\n",
       " (203, 0),\n",
       " (203, 1),\n",
       " (203, 2),\n",
       " (203, 3),\n",
       " (204, 0),\n",
       " (204, 1),\n",
       " (204, 2),\n",
       " (204, 3),\n",
       " (205, 0),\n",
       " (205, 1),\n",
       " (205, 2),\n",
       " (205, 3),\n",
       " (206, 0),\n",
       " (206, 1),\n",
       " (206, 2),\n",
       " (206, 3),\n",
       " (207, 0),\n",
       " (207, 1),\n",
       " (207, 2),\n",
       " (207, 3),\n",
       " (208, 0),\n",
       " (208, 1),\n",
       " (208, 2),\n",
       " (208, 3),\n",
       " (209, 0),\n",
       " (209, 1),\n",
       " (209, 2),\n",
       " (209, 3),\n",
       " (210, 0),\n",
       " (210, 1),\n",
       " (210, 2),\n",
       " (210, 3),\n",
       " (211, 0),\n",
       " (211, 1),\n",
       " (211, 2),\n",
       " (211, 3),\n",
       " (212, 0),\n",
       " (212, 1),\n",
       " (212, 2),\n",
       " (212, 3),\n",
       " (213, 0),\n",
       " (213, 1),\n",
       " (213, 2),\n",
       " (213, 3),\n",
       " (214, 0),\n",
       " (214, 1),\n",
       " (214, 2),\n",
       " (214, 3),\n",
       " (215, 0),\n",
       " (215, 1),\n",
       " (215, 2),\n",
       " (215, 3),\n",
       " (216, 0),\n",
       " (216, 1),\n",
       " (216, 2),\n",
       " (216, 3),\n",
       " (217, 0),\n",
       " (217, 1),\n",
       " (217, 2),\n",
       " (217, 3),\n",
       " (218, 0),\n",
       " (218, 1),\n",
       " (218, 2),\n",
       " (218, 3),\n",
       " (219, 0),\n",
       " (219, 1),\n",
       " (219, 2),\n",
       " (219, 3),\n",
       " (220, 0),\n",
       " (220, 1),\n",
       " (220, 2),\n",
       " (220, 3),\n",
       " (221, 0),\n",
       " (221, 1),\n",
       " (221, 2),\n",
       " (221, 3),\n",
       " (222, 0),\n",
       " (222, 1),\n",
       " (222, 2),\n",
       " (222, 3),\n",
       " (223, 0),\n",
       " (223, 1),\n",
       " (223, 2),\n",
       " (223, 3),\n",
       " (224, 0),\n",
       " (224, 1),\n",
       " (224, 2),\n",
       " (224, 3),\n",
       " (225, 0),\n",
       " (225, 1),\n",
       " (225, 2),\n",
       " (225, 3),\n",
       " (226, 0),\n",
       " (226, 1),\n",
       " (226, 2),\n",
       " (226, 3),\n",
       " (227, 0),\n",
       " (227, 1),\n",
       " (227, 2),\n",
       " (227, 3),\n",
       " (228, 0),\n",
       " (228, 1),\n",
       " (228, 2),\n",
       " (228, 3),\n",
       " (229, 0),\n",
       " (229, 1),\n",
       " (229, 2),\n",
       " (229, 3),\n",
       " (230, 0),\n",
       " (230, 1),\n",
       " (230, 2),\n",
       " (230, 3),\n",
       " (231, 0),\n",
       " (231, 1),\n",
       " (231, 2),\n",
       " (231, 3),\n",
       " (232, 0),\n",
       " (232, 1),\n",
       " (232, 2),\n",
       " (232, 3),\n",
       " (233, 0),\n",
       " (233, 1),\n",
       " (233, 2),\n",
       " (233, 3),\n",
       " (234, 0),\n",
       " (234, 1),\n",
       " (234, 2),\n",
       " (234, 3),\n",
       " (235, 0),\n",
       " (235, 1),\n",
       " (235, 2),\n",
       " (235, 3),\n",
       " (236, 0),\n",
       " (236, 1),\n",
       " (236, 2),\n",
       " (236, 3),\n",
       " (237, 0),\n",
       " (237, 1),\n",
       " (237, 2),\n",
       " (237, 3),\n",
       " (238, 0),\n",
       " (238, 1),\n",
       " (238, 2),\n",
       " (238, 3),\n",
       " (239, 0),\n",
       " (239, 1),\n",
       " (239, 2),\n",
       " (239, 3),\n",
       " (240, 0),\n",
       " (240, 1),\n",
       " (240, 2),\n",
       " (240, 3),\n",
       " (241, 0),\n",
       " (241, 1),\n",
       " (241, 2),\n",
       " (241, 3),\n",
       " (242, 0),\n",
       " (242, 1),\n",
       " (242, 2),\n",
       " (242, 3),\n",
       " (243, 0),\n",
       " (243, 1),\n",
       " (243, 2),\n",
       " (243, 3),\n",
       " (244, 0),\n",
       " (244, 1),\n",
       " (244, 2),\n",
       " (244, 3),\n",
       " (245, 0),\n",
       " (245, 1),\n",
       " (245, 2),\n",
       " (245, 3),\n",
       " (246, 0),\n",
       " (246, 1),\n",
       " (246, 2),\n",
       " (246, 3),\n",
       " (247, 0),\n",
       " (247, 1),\n",
       " (247, 2),\n",
       " (247, 3),\n",
       " (248, 0),\n",
       " (248, 1),\n",
       " (248, 2),\n",
       " (248, 3),\n",
       " (249, 0),\n",
       " (249, 1),\n",
       " (249, 2),\n",
       " (249, 3),\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = [t for t in itertools.product(range(1000), range(4))]\n",
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itertools.combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    ">>> for i in count(10):\n",
    "...     if i > 20: \n",
    "...         break\n",
    "...     else:\n",
    "...         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    ">>> for i in count(10,2):\n",
    "...     if i > 20: \n",
    "...         break\n",
    "...     else:\n",
    "...         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    ">>> for i in islice(count(10), 5):\n",
    "...     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rectangle'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "polys = ['triangle', 'square', 'pentagon', 'rectangle']\n",
    "iterator = cycle(polys)\n",
    "next(iterator)\n",
    "\n",
    "next(iterator)\n",
    "\n",
    "next(iterator)\n",
    "\n",
    "next(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345608"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list('12345678')\n",
    "a[0] = a[6] = 0\n",
    "a[1] = a[-7]\n",
    "a = int(''.join([str(i) for i in a]))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 36, 44, 48, 16, 24]\n"
     ]
    }
   ],
   "source": [
    "foo = [2, 18, 9, 22,17,24,8,12,27]\n",
    "a = list(filter(lambda x: x%3 == 0, foo))\n",
    "a = list(filter(lambda x: x%2 == 0, foo))\n",
    "a=map(lambda x:x*2,a)\n",
    "print(list(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1051\n"
     ]
    }
   ],
   "source": [
    "def func(a):\n",
    "    c=a\n",
    "    c[0]+=51\n",
    "\n",
    "b= [1000]\n",
    "print(b[0])\n",
    "func(b)\n",
    "print(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [1,2,2]*-2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b='abcd'\n",
    "for i in range(len(b)-2):\n",
    "    b[i].upper()\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eception C\n",
      "Div 5 succ\n"
     ]
    }
   ],
   "source": [
    "class C(Exception):\n",
    "    pass\n",
    "\n",
    "b = 1000\n",
    "try:\n",
    "    b/=b\n",
    "    raise C()\n",
    "\n",
    "except C:\n",
    "    print(\"Eception C\")\n",
    "else:\n",
    "    print(\"Div Succ\")\n",
    "\n",
    "try:\n",
    "    b=b/5\n",
    "except Exception as e:\n",
    "    print(\"inse exp blk\")\n",
    "else:\n",
    "    print(\"Div 5 succ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
